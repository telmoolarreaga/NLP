{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Antes de empezar con la explicación de esta entrega, debemos mencionar la corrección de dos errores de la entrega anterior. Hemos corregido el fallo de  aplicar stemming y lemmatización  tanto a TF-IDF como a embeddings. Ahora, solo se aplcia a TD-IDF. Además, adaptamos el Word2Vec para que no tuviese más de 30 epochs.\n",
        "\n",
        "Por otro lado, hemos sido capaces de aplicar shallow learning a las tres tareas de clasificación que teníamos previstas. Sin embargo, solo hemos logrado implementar deep learning y la comparación de embeddings a la clasificación de sesgo. Las dos tareas restantes estarán completadas para la siguiente entrega."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqfT1kYc_EOn"
      },
      "source": [
        "# **1. Shallow Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "from gensim.models import Word2Vec, FastText\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Embedding, Input\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from xgboost import XGBClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para representar los textos, hemos elegido TF-IDF para capturar la importancia relativa de cada palabra en un documento frente al corpus completo, reduciendo el peso de palabras muy frecuentes que no aportan información discriminativa, como artículos y preposiciones en inglés. Hemos establecido un límite de 3,000 palabras más importantes para reducir la dimensionalidad. Además, hemos añadido unigramas y bigramas para capturar algo de contexto local sin sobrecargar el modelo. Por otro lado, hemos eliminado las palabras vacías en inglés para centrar el análisis en palabras significativas. Esta representación genera vectores dispersos que son ideales para los modelos clásicos que usamos.\n",
        "\n",
        "Hemos seleccionado cuatro modelos para evaluar el desempeño: Logistic Regression, LinearSVC, Random Forest y XGBoost. Esta combinación nos permite cubrir tanto modelos lineales como no lineales y comparar rapidez, precisión y estabilidad.\n",
        "\n",
        "Antes de entrenar, hemos convertido los textos a números mediante label encoding, y realizado una división de train/validation del 80/20 para medir el rendimiento real y evitar overfitting. Además, hemos filtrado las clases con menos de dos registros, ya que la validación estratificada requiere al menos dos ejemplos por clase. La función recibe como parámetro la variable objetivo. En este caso, recibe las variables \"bias\", \"topic\" y \"source\", que son nuestras variables a clasificar.\n",
        "\n",
        "Finalmente, todos los modelos y el vectorizador TF-IDF han sido guardados para su reutilización. Este pipeline de Shallow Learning funciona como un baseline sólido que nos permite medir la mejora que aportan las representaciones densas y contextuales de texto que se utilizarán en las fases posteriores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def shallow_pipeline(df, target_col):\n",
        "    # Preparamos el texto\n",
        "    if \"text_joined\" not in df.columns:\n",
        "        df[\"text_joined\"] = df[\"tokens\"].apply(lambda x: \" \".join(x))\n",
        "    texts = df[\"text_joined\"].astype(str).tolist()\n",
        "    labels = df[target_col].tolist()\n",
        "\n",
        "    # Filtramos las clases con menos de 2 registros\n",
        "    counts = Counter(labels)\n",
        "    valid_classes = [c for c, cnt in counts.items() if cnt > 1]\n",
        "    mask = [lbl in valid_classes for lbl in labels]\n",
        "    texts = [t for t, m in zip(texts, mask) if m]\n",
        "    labels = [l for l, m in zip(labels, mask) if m]\n",
        "\n",
        "    # Codificamos las etiquetas\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(labels)\n",
        "\n",
        "    # Hacemos el train/validation split\n",
        "    X_train_text, X_val_text, y_train, y_val = train_test_split(\n",
        "        texts, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Aplicamos TF-IDF\n",
        "    vectorizer = TfidfVectorizer(max_features=3000, stop_words='english', ngram_range=(1,2))\n",
        "    X_train = vectorizer.fit_transform(X_train_text)\n",
        "    X_val = vectorizer.transform(X_val_text)\n",
        "\n",
        "    # Definimos los modelos\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegression(max_iter=1000, n_jobs=-1),\n",
        "        \"LinearSVC\": LinearSVC(),\n",
        "        \"Random Forest\": RandomForestClassifier(n_estimators=150, n_jobs=-1),\n",
        "       # \"XGBoost\": XGBClassifier(n_estimators=75, eval_metric=\"mlogloss\", tree_method=\"hist\", n_jobs=-1)\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # Entrenamos, evaluamos y guardamos los modelos\n",
        "    os.makedirs(\"data/models\", exist_ok=True)\n",
        "    for name, model in models.items():\n",
        "        print(f\"Entrenando {name}...\")\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_val)\n",
        "        results[name] = {\n",
        "            \"Accuracy\": accuracy_score(y_val, y_pred),\n",
        "            \"Macro-F1\": f1_score(y_val, y_pred, average=\"macro\")\n",
        "        }\n",
        "        # Guardamos el modelo\n",
        "        pickle.dump(model, open(f\"data/models/{name.replace(' ', '_').lower()}.pkl\", \"wb\"))\n",
        "\n",
        "    # Guardamos el vectorizador\n",
        "    os.makedirs(\"data/features\", exist_ok=True)\n",
        "    pickle.dump(vectorizer, open(\"data/features/tfidf_vectorizer.pkl\", \"wb\"))\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hemos tenido que incluir un filtro para eliminar las clases que tenían menos de dos registros antes de hacer el train_test_split. Esto se debe a que tuvimos un error al utilizar el parámetro stratify=y, que requiere al menos dos ejemplos por clase para poder crear correctamente los conjuntos de entrenamiento y validación de manera estratificada. Sin este filtro, cualquier clase con un único ejemplo provocaría que la ejecución se detuviera, como ocurría previamente con la variable source. Al aplicar este filtrado, nos aseguramos de que solo se utilicen clases con suficiente cantidad de datos, garantizando que la partición estratificada funcione y evitando que el pipeline falle durante el entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los resultados se analizarán en la sección 4 de este noteebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_pickle(\"data/data_clean/train_tokenized.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenando Logistic Regression...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenando LinearSVC...\n",
            "Entrenando Random Forest...\n",
            "                     Accuracy  Macro-F1\n",
            "Logistic Regression  0.702109  0.700091\n",
            "LinearSVC            0.698713  0.696551\n",
            "Random Forest        0.693710  0.690578\n"
          ]
        }
      ],
      "source": [
        "# Llamamos a la función con bias\n",
        "results_bias = shallow_pipeline(df, \"bias\")\n",
        "print(pd.DataFrame(results_bias).T)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenando Logistic Regression...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenando LinearSVC...\n",
            "Entrenando Random Forest...\n",
            "                     Accuracy  Macro-F1\n",
            "Logistic Regression  0.581129  0.338987\n",
            "LinearSVC            0.589171  0.410156\n",
            "Random Forest        0.520372  0.244504\n"
          ]
        }
      ],
      "source": [
        "# Llamamos a la función con topic\n",
        "results_topic = shallow_pipeline(df, \"topic\")\n",
        "print(pd.DataFrame(results_topic).T)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenando Logistic Regression...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenando LinearSVC...\n",
            "Entrenando Random Forest...\n",
            "                     Accuracy  Macro-F1\n",
            "Logistic Regression  0.503401  0.103117\n",
            "LinearSVC            0.559076  0.219572\n",
            "Random Forest        0.499642  0.127022\n"
          ]
        }
      ],
      "source": [
        "# Llamamos a la función con source\n",
        "results_source = shallow_pipeline(df, \"source\")\n",
        "print(pd.DataFrame(results_source).T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztbnwVJVWSgX"
      },
      "source": [
        "# **2. Modelos Deep**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En la parte de Deep Learning, hemos optado por utilizar redes neuronales recurrentes, específicamente LSTM y GRU, debido a su capacidad para capturar dependencias secuenciales en el texto. A diferencia de los modelos de Shallow Learning, que tratan cada palabra o n-grama de manera independiente, las RNNs permiten que la red recuerde información contextual de palabras anteriores en la secuencia, lo cual es crucial para nuestras tareas de clasificación de texto, donde el significado puede depender del orden de las palabras.\n",
        "\n",
        "Para la representación de los textos, hemos empleado embeddings densos, utilizando tres enfoques distintos con Word2Vec: congelado, fine-tune y desde cero. En el caso de los embeddings congelados, utilizamos un modelo preentrenado de Word2Vec y lo fijamos durante el entrenamiento de la red, de manera que solo la LSTM o GRU aprenda a combinar los vectores preexistentes. Esto permite evaluar cuánto conocimiento semántico ya capturado en Word2Vec puede ayudar a la tarea sin modificarlo. En el enfoque de fine-tune, los embeddings inicializados con Word2Vec se ajustan durante el entrenamiento, permitiendo que la red adapte los vectores a las particularidades del dataset específico. Finalmente, la opción de embeddings entrenados desde cero crea vectores aleatorios que se aprenden completamente durante el entrenamiento, lo que permite que la red descubra representaciones óptimas para la tarea, aunque requiere más datos y tiempo de entrenamiento.\n",
        "\n",
        "Hemos elegido LSTM y GRU, ya que cumple nuestra necesidad de comparar dos variantes de redes recurrentes: las LSTM tienen una mayor capacidad para capturar dependencias de largo plazo mediante su mecanismo de puertas, mientras que las GRU son más simples y computacionalmente eficientes, lo que puede acelerar el entrenamiento sin perder demasiado rendimiento.\n",
        "\n",
        "Los textos se transforman primero en secuencias de índices según el vocabulario de Word2Vec o un tokenizer entrenado sobre el dataset, y se aplica padding para unificar la longitud de las secuencias. Esto asegura que las redes puedan procesar lotes de datos de manera eficiente. Finalmente, la capa de salida utiliza softmax para producir probabilidades sobre las clases, y la red se entrena con categorical crossentropy, optimizando la accuracy y el macro-F1 como métricas de desempeño, lo cual es consistente con la evaluación utilizada en la parte de Shallow Learning.\n",
        "\n",
        "En conclusión, este apartado permite que nuestra red aprenda tanto representaciones densas de palabras como patrones secuenciales de las oraciones, ofreciendo una ventaja sobre los modelos lineales y de ensamble de Shallow Learning que solo utilizan información superficial y dispersa de los textos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Embeddings fine-tuneados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 567ms/step - accuracy: 0.4150 - loss: 1.0662 - val_accuracy: 0.4610 - val_loss: 1.0382\n",
            "Epoch 2/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 563ms/step - accuracy: 0.5123 - loss: 0.9728 - val_accuracy: 0.4803 - val_loss: 1.0051\n",
            "Epoch 3/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 610ms/step - accuracy: 0.5791 - loss: 0.8858 - val_accuracy: 0.5013 - val_loss: 0.9718\n",
            "Epoch 4/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 458ms/step - accuracy: 0.6515 - loss: 0.7710 - val_accuracy: 0.5127 - val_loss: 1.0037\n",
            "Epoch 5/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 564ms/step - accuracy: 0.7315 - loss: 0.6269 - val_accuracy: 0.5096 - val_loss: 1.1131\n",
            "Epoch 6/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 512ms/step - accuracy: 0.8044 - loss: 0.4847 - val_accuracy: 0.5037 - val_loss: 1.2262\n",
            "Epoch 1/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 393ms/step - accuracy: 0.3974 - loss: 1.0817 - val_accuracy: 0.4224 - val_loss: 1.0602\n",
            "Epoch 2/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 425ms/step - accuracy: 0.4762 - loss: 1.0127 - val_accuracy: 0.4596 - val_loss: 1.0251\n",
            "Epoch 3/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 400ms/step - accuracy: 0.5726 - loss: 0.8917 - val_accuracy: 0.5077 - val_loss: 0.9731\n",
            "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Cargar dataset y etiquetas\n",
        "# ----------------------------\n",
        "df_train = pd.read_pickle(\"data/data_clean/train_tokenized.pkl\")\n",
        "y = df_train[\"bias\"].values\n",
        "\n",
        "# Codificamos las labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "y_cat = to_categorical(y_encoded)\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Train / Val / Test split\n",
        "# ----------------------------\n",
        "# Primero train + temp (val+test)\n",
        "X_train_texts, X_temp_texts, y_train, y_temp = train_test_split(\n",
        "    df_train[\"tokens\"], y_cat, test_size=0.3, random_state=42, stratify=y_cat\n",
        ")\n",
        "\n",
        "# Luego temp → val + test\n",
        "X_val_texts, X_test_texts, y_val, y_test = train_test_split(\n",
        "    X_temp_texts, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Word2Vec embeddings\n",
        "# ----------------------------\n",
        "w2v_model = Word2Vec.load(\"data/embeddings/word2vec.model\")\n",
        "embedding_dim = w2v_model.vector_size\n",
        "word_index = {word: i+1 for i, word in enumerate(w2v_model.wv.index_to_key)}\n",
        "vocab_size = len(word_index) + 1  # +1 para padding\n",
        "\n",
        "def tokens_to_indices(tokens, word_index):\n",
        "    return [word_index[t] for t in tokens if t in word_index]\n",
        "\n",
        "X_train_idx = [tokens_to_indices(t, word_index) for t in X_train_texts]\n",
        "X_val_idx = [tokens_to_indices(t, word_index) for t in X_val_texts]\n",
        "X_test_idx = [tokens_to_indices(t, word_index) for t in X_test_texts]\n",
        "\n",
        "max_seq_len = 200\n",
        "X_train_pad = pad_sequences(X_train_idx, maxlen=max_seq_len, padding='post')\n",
        "X_val_pad = pad_sequences(X_val_idx, maxlen=max_seq_len, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_idx, maxlen=max_seq_len, padding='post')\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_matrix[i] = w2v_model.wv[word]\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Definición del modelo RNN\n",
        "# ----------------------------\n",
        "def build_rnn(model_type='LSTM'):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=vocab_size,\n",
        "                        output_dim=embedding_dim,\n",
        "                        weights=[embedding_matrix],\n",
        "                        input_length=max_seq_len,\n",
        "                        trainable=True))  # Fine-tune embeddings\n",
        "    if model_type == 'LSTM':\n",
        "        model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "    elif model_type == 'GRU':\n",
        "        model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(y_cat.shape[1], activation='softmax'))\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-3),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# ----------------------------\n",
        "# 5. Early stopping\n",
        "# ----------------------------\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 6. Entrenamiento y evaluación\n",
        "# ----------------------------\n",
        "# LSTM\n",
        "lstm_model = build_rnn('LSTM')\n",
        "lstm_history = lstm_model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# GRU\n",
        "gru_model = build_rnn('GRU')\n",
        "gru_history = gru_model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 7. Predicciones sobre TEST\n",
        "# ----------------------------\n",
        "y_pred_lstm = np.argmax(lstm_model.predict(X_test_pad, batch_size=64), axis=1)\n",
        "y_pred_gru = np.argmax(gru_model.predict(X_test_pad, batch_size=64), axis=1)\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# ----------------------------\n",
        "# 8. Métricas finales\n",
        "# ----------------------------\n",
        "results = {\n",
        "    'LSTM': {\n",
        "        'Accuracy': accuracy_score(y_test_labels, y_pred_lstm),\n",
        "        'Macro-F1': f1_score(y_test_labels, y_pred_lstm, average='macro')\n",
        "    },\n",
        "    'GRU': {\n",
        "        'Accuracy': accuracy_score(y_test_labels, y_pred_gru),\n",
        "        'Macro-F1': f1_score(y_test_labels, y_pred_gru, average='macro')\n",
        "    }\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"Resultados finales sobre TEST:\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Embeddings no finetuneados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Creamos la  columna text_joined a partir de tokens\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mtext_joined\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mtokens\u001b[39m\u001b[33m\"\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(x))\n\u001b[32m      4\u001b[39m texts = df[\u001b[33m\"\u001b[39m\u001b[33mtext_joined\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).tolist()\n\u001b[32m      5\u001b[39m labels = df[\u001b[33m\"\u001b[39m\u001b[33mbias\u001b[39m\u001b[33m\"\u001b[39m].tolist()\n",
            "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Creamos la columna text_joined a partir de tokens\n",
        "df[\"text_joined\"] = df[\"tokens\"].apply(lambda x: \" \".join(x))\n",
        "\n",
        "texts = df[\"text_joined\"].astype(str).tolist()\n",
        "labels = df[\"bias\"].tolist()\n",
        "\n",
        "# Tokenización y secuencias\n",
        "vocab_size = 20000\n",
        "maxlen = 100\n",
        "embedding_dim = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "X_seq = tokenizer.texts_to_sequences(texts)\n",
        "X = pad_sequences(X_seq, maxlen=maxlen)\n",
        "\n",
        "# Codificamos las etiquetas\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(labels)\n",
        "\n",
        "# Train / Validation / Test split (60/20/20)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Funciones para LSTM y GRU\n",
        "def build_lstm_model():\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim, input_length=maxlen, trainable=False),\n",
        "        LSTM(128, return_sequences=False),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(len(np.unique(y)), activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "def build_gru_model():\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim, input_length=maxlen, trainable=False),\n",
        "        GRU(128, return_sequences=False),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(len(np.unique(y)), activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Entrenamiento\n",
        "lstm_model = build_lstm_model()\n",
        "history_lstm = lstm_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "gru_model = build_gru_model()\n",
        "history_gru = gru_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluación por clase\n",
        "def evaluate(model, X_test, y_test):\n",
        "    preds = np.argmax(model.predict(X_test, batch_size=64), axis=1)\n",
        "    print(classification_report(y_test, preds, target_names=le.classes_))\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    f1 = f1_score(y_test, preds, average='macro')\n",
        "    return acc, f1\n",
        "\n",
        "print(\"\\nResultados Embedding Random (NO fine-tuneado)\")\n",
        "acc_lstm, f1_lstm = evaluate(lstm_model, X_test, y_test)\n",
        "acc_gru, f1_gru = evaluate(gru_model, X_test, y_test)\n",
        "\n",
        "# Guardamos resultados en DataFrame\n",
        "results_df = pd.DataFrame({\n",
        "    'Model': ['LSTM', 'GRU'],\n",
        "    'Accuracy': [acc_lstm, acc_gru],\n",
        "    'Macro-F1': [f1_lstm, f1_gru]\n",
        "})\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Word2Vec congelado vs Word2Vec fine-tuneado vs Word2Vec from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 737ms/step - accuracy: 0.4120 - loss: 1.0719 - val_accuracy: 0.4355 - val_loss: 1.0549\n",
            "Epoch 2/5\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 1s/step - accuracy: 0.4564 - loss: 1.0241 - val_accuracy: 0.4694 - val_loss: 1.0021\n",
            "Epoch 3/5\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 575ms/step - accuracy: 0.4739 - loss: 0.9988 - val_accuracy: 0.4682 - val_loss: 0.9979\n",
            "Epoch 4/5\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 575ms/step - accuracy: 0.4852 - loss: 0.9866 - val_accuracy: 0.4973 - val_loss: 0.9732\n",
            "Epoch 5/5\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 433ms/step - accuracy: 0.4917 - loss: 0.9776 - val_accuracy: 0.4993 - val_loss: 0.9686\n",
            "Epoch 1/5\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 398ms/step - accuracy: 0.4306 - loss: 1.0563 - val_accuracy: 0.4725 - val_loss: 1.0097\n",
            "Epoch 2/5\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 510ms/step - accuracy: 0.5197 - loss: 0.9549 - val_accuracy: 0.4961 - val_loss: 0.9732\n",
            "Epoch 3/5\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 349ms/step - accuracy: 0.5951 - loss: 0.8587 - val_accuracy: 0.5075 - val_loss: 0.9620\n",
            "Epoch 4/5\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 489ms/step - accuracy: 0.6678 - loss: 0.7425 - val_accuracy: 0.5048 - val_loss: 1.0228\n",
            "Epoch 5/5\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 510ms/step - accuracy: 0.7385 - loss: 0.6043 - val_accuracy: 0.5023 - val_loss: 1.1309\n",
            "Epoch 1/5\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 372ms/step - accuracy: 0.3844 - loss: 1.0861 - val_accuracy: 0.4466 - val_loss: 1.0464\n",
            "Epoch 2/5\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 416ms/step - accuracy: 0.4685 - loss: 1.0323 - val_accuracy: 0.4500 - val_loss: 1.0501\n",
            "Epoch 3/5\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 348ms/step - accuracy: 0.5128 - loss: 0.9844 - val_accuracy: 0.4698 - val_loss: 1.0237\n",
            "Epoch 4/5\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 400ms/step - accuracy: 0.5701 - loss: 0.9108 - val_accuracy: 0.4727 - val_loss: 1.0337\n",
            "Epoch 5/5\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 345ms/step - accuracy: 0.6291 - loss: 0.8218 - val_accuracy: 0.4921 - val_loss: 1.0518\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step\n",
            "                    Accuracy  Macro-F1\n",
            "Word2Vec Frozen     0.499285  0.487054\n",
            "Word2Vec Fine-tune  0.502323  0.502254\n",
            "Word2Vec Scratch    0.492137  0.487125\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Cargamos el dataset tokenizado\n",
        "df = pd.read_pickle(\"data/data_clean/train_tokenized.pkl\")\n",
        "df[\"text_joined\"] = df[\"tokens\"].apply(lambda x: \" \".join(x))\n",
        "\n",
        "texts = df[\"tokens\"].tolist()\n",
        "labels = df[\"bias\"].tolist()\n",
        "\n",
        "# Codificamos las etiquetas\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(labels)\n",
        "\n",
        "# Train / Validation / Test split (60/20/20)\n",
        "X_train_text, X_temp_text, y_train, y_temp = train_test_split(texts, y, test_size=0.4, random_state=42, stratify=y)\n",
        "X_val_text, X_test_text, y_val, y_test = train_test_split(X_temp_text, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Cargamos el Word2Vec preentrenado\n",
        "w2v_model = Word2Vec.load(\"data/embeddings/word2vec.model\")\n",
        "embedding_dim = w2v_model.vector_size\n",
        "\n",
        "word_index = {word: i+1 for i, word in enumerate(w2v_model.wv.index_to_key)}\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "def tokens_to_indices(tokens, word_index):\n",
        "    return [word_index[t] for t in tokens if t in word_index]\n",
        "\n",
        "X_train_idx = [tokens_to_indices(t, word_index) for t in X_train_text]\n",
        "X_val_idx = [tokens_to_indices(t, word_index) for t in X_val_text]\n",
        "X_test_idx = [tokens_to_indices(t, word_index) for t in X_test_text]\n",
        "\n",
        "max_seq_len = 200\n",
        "X_train_pad = pad_sequences(X_train_idx, maxlen=max_seq_len, padding='post')\n",
        "X_val_pad = pad_sequences(X_val_idx, maxlen=max_seq_len, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_idx, maxlen=max_seq_len, padding='post')\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_matrix[i] = w2v_model.wv[word]\n",
        "\n",
        "# Función para LSTM con embeddings preentrenados\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "def build_lstm_model(embedding_matrix, trainable=True):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(\n",
        "        input_dim=embedding_matrix.shape[0],\n",
        "        output_dim=embedding_matrix.shape[1],\n",
        "        weights=[embedding_matrix],\n",
        "        input_length=max_seq_len,\n",
        "        trainable=trainable\n",
        "    ))\n",
        "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(optimizer=Adam(1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Word2Vec Frozen\n",
        "lstm_frozen = build_lstm_model(embedding_matrix, trainable=False)\n",
        "history_frozen = lstm_frozen.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Word2Vec Fine-tune\n",
        "lstm_finetune = build_lstm_model(embedding_matrix, trainable=True)\n",
        "history_finetune = lstm_finetune.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Word2Vec Scratch\n",
        "embedding_matrix_random = np.random.normal(size=(vocab_size, embedding_dim))\n",
        "lstm_scratch = build_lstm_model(embedding_matrix_random, trainable=True)\n",
        "history_scratch = lstm_scratch.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluación por clase\n",
        "def evaluate(model, X_test, y_test):\n",
        "    preds = np.argmax(model.predict(X_test, batch_size=64), axis=1)\n",
        "    print(classification_report(y_test, preds, target_names=le.classes_))\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    f1 = f1_score(y_test, preds, average='macro')\n",
        "    return acc, f1\n",
        "\n",
        "results = {}\n",
        "print(\"\\nResultados Word2Vec Frozen\")\n",
        "results['Word2Vec Frozen'] = evaluate(lstm_frozen, X_test_pad, y_test)\n",
        "\n",
        "print(\"\\nResultados Word2Vec Fine-tune\")\n",
        "results['Word2Vec Fine-tune'] = evaluate(lstm_finetune, X_test_pad, y_test)\n",
        "\n",
        "print(\"\\nResultados Word2Vec Scratch\")\n",
        "results['Word2Vec Scratch'] = evaluate(lstm_scratch, X_test_pad, y_test)\n",
        "\n",
        "results_df = pd.DataFrame(results, index=['Accuracy','Macro-F1']).T\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **3. Comparación de Embeddings**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En esta sección se consideran distintas técnicas de representación de texto para tareas de clasificación orientadas a la detección de sesgos ideológicos, tema y medio en artículos periodísticos. Para ello se analizan enfoques tradicionales, embeddings no contextuales y embeddings contextuales, con el objetivo de entender cómo cada representación captura información relevante del lenguaje dentro de este dominio específico.\n",
        "\n",
        "Los métodos tradicionales, como TF-IDF y Bag-of-Words (BoW), representan el texto mediante vectores dispersos basados únicamente en la frecuencia o presencia de términos, sin tener en cuenta el word order ni el context. Se espera que estos enfoques funcionen bien cuando ciertas palabras clave o expresiones son indicadores directos de postura ideológica o del tema tratado. Sin embargo, su capacidad para capturar matices ideológicos sutiles, estructuras discursivas o patrones retóricos es limitada debido a la ausencia de información contextual.\n",
        "\n",
        "Los embeddings no contextuales, como Word2Vec y FastText, generan dense word vectors aprendidos a partir de coocurrencias en un corpus. Estos modelos son capaces de capturar similitudes semánticas entre palabras y asociaciones típicas del lenguaje periodístico, lo que ayuda a identificar vocabulario característico de ciertos medios o tendencias ideológicas. Aunque estos embeddings proporcionan una representación más rica que los métodos tradicionales, no distinguen los diferentes significados de una palabra según el contexto en el que aparece. En el caso de FastText, el uso de subword embeddings permite manejar mejor palabras raras, neologismos o términos específicos de determinados medios.\n",
        "\n",
        "Finalmente, los embeddings contextuales, como Sentence Transformers o BERT, generan representaciones que dependen del contexto completo de la oración o del documento. Esto permite que una misma palabra tenga diferentes vectores según su significado en el artículo, capturando relaciones semánticas complejas, long-range dependencies y matices ideológicos implícitos. Se espera que estos modelos sean especialmente efectivos para detectar bias más sutil, diferencias discursivas entre medios y patrones retóricos que dependen del estilo o la narrativa del artículo. No obstante, este tipo de modelos suele requerir un mayor volumen de datos y mayor capacidad computacional para ajustarse correctamente a tareas especializadas como la clasificación ideológica o la identificación del medio.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3.1 Embeddings tradicionales**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TF-IDF</th>\n",
              "      <td>0.703002</td>\n",
              "      <td>0.702330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bag-of-Words</th>\n",
              "      <td>0.646712</td>\n",
              "      <td>0.646754</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Accuracy  F1-score\n",
              "TF-IDF        0.703002  0.702330\n",
              "Bag-of-Words  0.646712  0.646754"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Cargamos y preparamos los datos\n",
        "df_train = pd.read_pickle(\"data/data_clean/train_tokenized.pkl\")\n",
        "df_train[\"text_joined\"] = df_train[\"tokens\"].apply(lambda x: \" \".join(x))\n",
        "texts = df_train[\"text_joined\"].tolist()\n",
        "y = df_train[\"bias\"].values\n",
        "\n",
        "results = {}\n",
        "\n",
        "# -------------------\n",
        "# Train / Val / Test\n",
        "# -------------------\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(texts, y, test_size=0.2, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)\n",
        "# Esto da 60% train / 20% val / 20% test\n",
        "\n",
        "# -------------------\n",
        "# TF-IDF\n",
        "# -------------------\n",
        "tfidf = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1,2))\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_val_tfidf = tfidf.transform(X_val)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "y_val_pred = clf.predict(X_val_tfidf)\n",
        "y_test_pred = clf.predict(X_test_tfidf)\n",
        "\n",
        "results[\"TF-IDF\"] = {\n",
        "    \"Val Accuracy\": accuracy_score(y_val, y_val_pred),\n",
        "    \"Test Accuracy\": accuracy_score(y_test, y_test_pred),\n",
        "    \"Val F1 (weighted)\": f1_score(y_val, y_val_pred, average=\"weighted\"),\n",
        "    \"Test F1 (weighted)\": f1_score(y_test, y_test_pred, average=\"weighted\")\n",
        "}\n",
        "\n",
        "print(\"TF-IDF - Classification Report (Test):\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# -------------------\n",
        "# Bag-of-Words\n",
        "# -------------------\n",
        "bow = CountVectorizer(max_features=5000, stop_words='english', ngram_range=(1,2))\n",
        "X_train_bow = bow.fit_transform(X_train)\n",
        "X_val_bow = bow.transform(X_val)\n",
        "X_test_bow = bow.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_bow, y_train)\n",
        "\n",
        "y_val_pred = clf.predict(X_val_bow)\n",
        "y_test_pred = clf.predict(X_test_bow)\n",
        "\n",
        "results[\"Bag-of-Words\"] = {\n",
        "    \"Val Accuracy\": accuracy_score(y_val, y_val_pred),\n",
        "    \"Test Accuracy\": accuracy_score(y_test, y_test_pred),\n",
        "    \"Val F1 (weighted)\": f1_score(y_val, y_val_pred, average=\"weighted\"),\n",
        "    \"Test F1 (weighted)\": f1_score(y_test, y_test_pred, average=\"weighted\")\n",
        "}\n",
        "\n",
        "print(\"Bag-of-Words - Classification Report (Test):\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# -------------------\n",
        "# Resultados\n",
        "# -------------------\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"\\nComparativa Embeddings Tradicionales:\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3.2 Embeddings no contextuales**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downstream (clustering) Word2Vec: 184242.40625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downstream (clustering) FastText: 258313.15625\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec, FastText\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Preparar tokens\n",
        "df_train = pd.read_pickle(\"data/data_clean/train_tokenized.pkl\")\n",
        "sentences = df_train[\"tokens\"].tolist()\n",
        "y = df_train[\"bias\"].values\n",
        "\n",
        "# Train / Val / Test split (60/20/20)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(sentences, y, test_size=0.2, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)\n",
        "\n",
        "results = {}\n",
        "\n",
        "# -------------------\n",
        "# Word2Vec\n",
        "# -------------------\n",
        "w2v_model = Word2Vec(sentences=X_train, vector_size=100, window=5, min_count=3, workers=1, sg=1)\n",
        "w2v_model.save(\"data/embeddings/word2vec.model\")\n",
        "\n",
        "# Promediar embeddings por frase\n",
        "def get_avg_w2v(sentence, model):\n",
        "    vecs = [model.wv[word] for word in sentence if word in model.wv]\n",
        "    if len(vecs) == 0:\n",
        "        return np.zeros(model.vector_size)\n",
        "    return np.mean(vecs, axis=0)\n",
        "\n",
        "X_train_vec = np.array([get_avg_w2v(s, w2v_model) for s in X_train])\n",
        "X_val_vec = np.array([get_avg_w2v(s, w2v_model) for s in X_val])\n",
        "X_test_vec = np.array([get_avg_w2v(s, w2v_model) for s in X_test])\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_vec, y_train)\n",
        "y_val_pred = clf.predict(X_val_vec)\n",
        "y_test_pred = clf.predict(X_test_vec)\n",
        "\n",
        "results[\"Word2Vec\"] = {\n",
        "    \"Val Accuracy\": accuracy_score(y_val, y_val_pred),\n",
        "    \"Test Accuracy\": accuracy_score(y_test, y_test_pred),\n",
        "    \"Val F1 (weighted)\": f1_score(y_val, y_val_pred, average=\"weighted\"),\n",
        "    \"Test F1 (weighted)\": f1_score(y_test, y_test_pred, average=\"weighted\")\n",
        "}\n",
        "\n",
        "print(\"Word2Vec - Classification Report (Test):\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# -------------------\n",
        "# FastText\n",
        "# -------------------\n",
        "fasttext_model = FastText(sentences=X_train, vector_size=100, window=5, min_count=3, workers=1, sg=1)\n",
        "fasttext_model.save(\"data/embeddings/fasttext.model\")\n",
        "\n",
        "X_train_vec = np.array([get_avg_w2v(s, fasttext_model) for s in X_train])\n",
        "X_val_vec = np.array([get_avg_w2v(s, fasttext_model) for s in X_val])\n",
        "X_test_vec = np.array([get_avg_w2v(s, fasttext_model) for s in X_test])\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_vec, y_train)\n",
        "y_val_pred = clf.predict(X_val_vec)\n",
        "y_test_pred = clf.predict(X_test_vec)\n",
        "\n",
        "results[\"FastText\"] = {\n",
        "    \"Val Accuracy\": accuracy_score(y_val, y_val_pred),\n",
        "    \"Test Accuracy\": accuracy_score(y_test, y_test_pred),\n",
        "    \"Val F1 (weighted)\": f1_score(y_val, y_val_pred, average=\"weighted\"),\n",
        "    \"Test F1 (weighted)\": f1_score(y_test, y_test_pred, average=\"weighted\")\n",
        "}\n",
        "\n",
        "print(\"FastText - Classification Report (Test):\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# -------------------\n",
        "# Resultados finales\n",
        "# -------------------\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"\\nComparativa Embeddings No Contextuales:\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3.3 Embeddings contextuales**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b941977a2d1042f78724d780b1ec103d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/875 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence Transformers - Accuracy: 0.5394924946390279\n",
            "Sentence Transformers - F1 Score: 0.5379302986979321\n",
            "BERT - Accuracy: 0.3\n",
            "BERT - F1 Score: 0.25047619047619046\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Preparar textos\n",
        "df_train = pd.read_pickle(\"data/data_clean/train_tokenized.pkl\")\n",
        "df_train[\"text_joined\"] = df_train[\"tokens\"].apply(lambda x: \" \".join(x))\n",
        "texts = df_train[\"text_joined\"].tolist()\n",
        "y = df_train[\"bias\"].values\n",
        "\n",
        "# Train / Val / Test split\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(texts, y, test_size=0.2, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)\n",
        "\n",
        "results = {}\n",
        "\n",
        "# -------------------\n",
        "# Sentence Transformers\n",
        "# -------------------\n",
        "st_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "X_train_vec = st_model.encode(X_train, batch_size=32, show_progress_bar=True)\n",
        "X_val_vec = st_model.encode(X_val, batch_size=32)\n",
        "X_test_vec = st_model.encode(X_test, batch_size=32)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_vec, y_train)\n",
        "y_val_pred = clf.predict(X_val_vec)\n",
        "y_test_pred = clf.predict(X_test_vec)\n",
        "\n",
        "results[\"Sentence Transformers\"] = {\n",
        "    \"Val Accuracy\": accuracy_score(y_val, y_val_pred),\n",
        "    \"Test Accuracy\": accuracy_score(y_test, y_test_pred),\n",
        "    \"Val F1 (weighted)\": f1_score(y_val, y_val_pred, average=\"weighted\"),\n",
        "    \"Test F1 (weighted)\": f1_score(y_test, y_test_pred, average=\"weighted\")\n",
        "}\n",
        "\n",
        "print(\"Sentence Transformers - Classification Report (Test):\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# -------------------\n",
        "# BERT (limitado a 100 textos para no saturar memoria)\n",
        "# -------------------\n",
        "bert_model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
        "bert_model = BertModel.from_pretrained(bert_model_name)\n",
        "bert_model.eval()\n",
        "\n",
        "def bert_sentence_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)\n",
        "        embeddings = outputs.last_hidden_state.squeeze(0)\n",
        "        return embeddings.mean(dim=0).numpy()\n",
        "\n",
        "X_train_subset = X_train[:100]\n",
        "X_val_subset = X_val[:20]\n",
        "X_test_subset = X_test[:20]\n",
        "y_train_subset = y_train[:100]\n",
        "y_val_subset = y_val[:20]\n",
        "y_test_subset = y_test[:20]\n",
        "\n",
        "X_train_vec = np.array([bert_sentence_embedding(t) for t in X_train_subset])\n",
        "X_val_vec = np.array([bert_sentence_embedding(t) for t in X_val_subset])\n",
        "X_test_vec = np.array([bert_sentence_embedding(t) for t in X_test_subset])\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_vec, y_train_subset)\n",
        "y_val_pred = clf.predict(X_val_vec)\n",
        "y_test_pred = clf.predict(X_test_vec)\n",
        "\n",
        "results[\"BERT\"] = {\n",
        "    \"Val Accuracy\": accuracy_score(y_val_subset, y_val_pred),\n",
        "    \"Test Accuracy\": accuracy_score(y_test_subset, y_test_pred),\n",
        "    \"Val F1 (weighted)\": f1_score(y_val_subset, y_val_pred, average=\"weighted\"),\n",
        "    \"Test F1 (weighted)\": f1_score(y_test_subset, y_test_pred, average=\"weighted\")\n",
        "}\n",
        "\n",
        "print(\"BERT - Classification Report (Test):\")\n",
        "print(classification_report(y_test_subset, y_test_pred))\n",
        "\n",
        "# -------------------\n",
        "# Resultados finales\n",
        "# -------------------\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"\\nComparativa Embeddings Contextuales:\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvy29jCJWbqI"
      },
      "source": [
        "# **4. Tabla Comparativa de Resultados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4.1 Shallow Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para entender los resultados, hay que aclarar los parámetros utilizados para cada variable en Shallow Learning.\n",
        "\n",
        "En el caso de la variable source, hemos tenido que reducir el número de estimadores del Random Forest de 300 a 150. Además, el número de estimadores del XGBoost también ha sido reducido de 200 a 75. Sin esta reducción, no habríamos sido capaces de terminar la ejecución de la celda. Ha llegado a estar más de una hora y seguía sin terminar de ejecutarse.\n",
        "\n",
        "En cuanto a la variable topic, además de las rebajas aplicadas al caso de la variable source, hemos decidido quitar el modelo XGBoost, ya que no termina de ejecutarse. Disponemos de equipos con capacidades técnicas muy limitadas, por lo que, con mejores ordenadores, no se tendrían que reducir los valores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Resultados de Clasificación Shallow Learning (TF-IDF)\n",
            "\n",
            "           Métricas     Bias             Topic            Source         \n",
            "              Model Accuracy Macro-F1 Accuracy Macro-F1 Accuracy Macro-F1\n",
            "Logistic Regression   0.7021   0.7001   0.5811   0.3390   0.5034   0.1031\n",
            "          LinearSVC   0.6987   0.6966   0.5892   0.4102   0.5591   0.2196\n",
            "      Random Forest   0.6839   0.6798   0.5197   0.2500   0.5000   0.1210\n",
            "            XGBoost   0.7346   0.7339   0.0000   0.0000   0.5326   0.2233\n"
          ]
        }
      ],
      "source": [
        "# Resultados de clasificación por variable objetivo\n",
        "results_bias = {\n",
        "    \"Logistic Regression\": {\"Accuracy\": 0.702109, \"Macro-F1\": 0.700091},\n",
        "    \"LinearSVC\": {\"Accuracy\": 0.698713, \"Macro-F1\": 0.696551},\n",
        "    \"Random Forest\": {\"Accuracy\": 0.683881, \"Macro-F1\": 0.679829},\n",
        "    \"XGBoost\": {\"Accuracy\": 0.734632, \"Macro-F1\": 0.733918}\n",
        "}\n",
        "\n",
        "results_topic = {\n",
        "    \"Logistic Regression\": {\"Accuracy\": 0.581129, \"Macro-F1\": 0.338987},\n",
        "    \"LinearSVC\": {\"Accuracy\": 0.589171, \"Macro-F1\": 0.410156},\n",
        "    \"Random Forest\": {\"Accuracy\": 0.519657, \"Macro-F1\": 0.250003},\n",
        "    \"XGBoost\": {\"Accuracy\": 0.0, \"Macro-F1\": 0.0}\n",
        "}\n",
        "\n",
        "results_source = {\n",
        "    \"Logistic Regression\": {\"Accuracy\": 0.503401, \"Macro-F1\": 0.103117},\n",
        "    \"LinearSVC\": {\"Accuracy\": 0.559076, \"Macro-F1\": 0.219572},\n",
        "    \"Random Forest\": {\"Accuracy\": 0.500000, \"Macro-F1\": 0.120979},\n",
        "    \"XGBoost\": {\"Accuracy\": 0.532581, \"Macro-F1\": 0.223251}\n",
        "}\n",
        "\n",
        "# --- Creación del DataFrame de Comparación ---\n",
        "rows = []\n",
        "models = [\"Logistic Regression\", \"LinearSVC\", \"Random Forest\", \"XGBoost\"]\n",
        "\n",
        "for model in models:\n",
        "    row = {\n",
        "        \"Model\": model,\n",
        "        \"Bias Accuracy\": results_bias[model][\"Accuracy\"],\n",
        "        \"Bias Macro-F1\": results_bias[model][\"Macro-F1\"],\n",
        "        \"Topic Accuracy\": results_topic[model][\"Accuracy\"],\n",
        "        \"Topic Macro-F1\": results_topic[model][\"Macro-F1\"],\n",
        "        \"Source Accuracy\": results_source[model][\"Accuracy\"],\n",
        "        \"Source Macro-F1\": results_source[model][\"Macro-F1\"]\n",
        "    }\n",
        "    rows.append(row)\n",
        "\n",
        "df_comparison = pd.DataFrame(rows)\n",
        "\n",
        "# --- Formateo para la presentación ---\n",
        "\n",
        "# Redondear todas las columnas de métricas a 4 decimales\n",
        "df_display = df_comparison.round(4)\n",
        "\n",
        "# Crear un multi-índice para los nombres de las columnas para agrupar las métricas\n",
        "cols = [('Métricas', 'Model'), \n",
        "        ('Bias', 'Accuracy'), ('Bias', 'Macro-F1'),\n",
        "        ('Topic', 'Accuracy'), ('Topic', 'Macro-F1'),\n",
        "        ('Source', 'Accuracy'), ('Source', 'Macro-F1')]\n",
        "\n",
        "df_display.columns = pd.MultiIndex.from_tuples(cols)\n",
        "\n",
        "# Imprimir la tabla\n",
        "print(\" Resultados de Clasificación Shallow Learning (TF-IDF)\\n\")\n",
        "# Usar to_markdown o to_string para una salida limpia en consola\n",
        "print(df_display.to_string(index=False))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los resultados de clasificación usando Shallow Learning con TF-IDF muestran un comportamiento variable según la tarea y el modelo. Para la tarea de Bias, todos los modelos presentan un desempeño sólido, con XGBoost liderando (accuracy 0.7346, macro-F1 0.7339) seguido de Logistic Regression y LinearSVC alrededor de 0.70 en ambas métricas. Esto indica que las diferencias de sesgo en los textos son relativamente fáciles de capturar con TF-IDF.\n",
        "\n",
        "En la tarea de Topic, los modelos lineales, especialmente LinearSVC, obtienen los mejores resultados (accuracy 0.5892, macro-F1 0.4102). La celda de XGBoost muestra 0, al no haberse aplicado este algoritmo a la tarea por los problemas de tiempo de ejecucion explicados anteriormente. Esto refuerza que, para la clasificación por tópicos, los modelos lineales son adecuados con TF-IDF, que captura bien los términos distintivos de cada tema.\n",
        "\n",
        "En la tarea de Source, el desempeño general es más bajo. LinearSVC alcanza un accuracy de 0.5591 y un macro-F1 de 0.2196, mientras que Logistic Regression y otros modelos muestran valores menores. Esto refleja la dificultad de diferenciar la fuente del texto únicamente con TF-IDF, ya que las diferencias estilísticas son menos evidentes en la representación basada en frecuencias de palabras.\n",
        "\n",
        "En resumen, los modelos lineales ofrecen resultados consistentes para Bias y Topic, mientras que los modelos de ensamble como Random Forest o XGBoost se aplican solo a algunas tareas y muestran fortalezas específicas. TF-IDF es útil para capturar patrones globales de sesgo y tópico, pero es limitado para distinguir la fuente de los textos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4.2 Deep Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Rendimiento de Modelos de Deep Learning (LSTM & GRU)\n",
            "\n",
            "Estrategia de Embedding   Modelo  Accuracy  Macro-F1\n",
            "  Finetuneado (Aprende)     LSTM    0.5134    0.5146\n",
            "  Finetuneado (Aprende)      GRU    0.5264    0.5265\n",
            "No Finetuneado (Random)     LSTM    0.3987    0.3339\n",
            "No Finetuneado (Random)      GRU    0.3858    0.3546\n",
            "      Word2Vec (Frozen) Word2Vec    0.4993    0.4871\n",
            "   Word2Vec (Fine-tune) Word2Vec    0.5023    0.5023\n",
            "     Word2Vec (Scratch) Word2Vec    0.4921    0.4871\n"
          ]
        }
      ],
      "source": [
        "# Datos proporcionados\n",
        "data_finetune = {\n",
        "    \"Modelo\": [\"LSTM\", \"GRU\"],\n",
        "    \"Estrategia de Embedding\": [\"Finetuneado (Aprende)\", \"Finetuneado (Aprende)\"],\n",
        "    \"Accuracy\": [0.513402, 0.526447],\n",
        "    \"Macro-F1\": [0.514574, 0.526548]\n",
        "}\n",
        "\n",
        "data_random = {\n",
        "    \"Modelo\": [\"LSTM\", \"GRU\"],\n",
        "    \"Estrategia de Embedding\": [\"No Finetuneado (Random)\", \"No Finetuneado (Random)\"],\n",
        "    \"Accuracy\": [0.39867762687634023, 0.3858112937812723],\n",
        "    \"Macro-F1\": [0.33385069350207125, 0.3545762899287412]\n",
        "}\n",
        "\n",
        "data_word2vec = {\n",
        "    \"Modelo\": [\"Word2Vec\", \"Word2Vec\", \"Word2Vec\"], # Usamos Word2Vec como modelo en este caso para distinguirlo\n",
        "    \"Estrategia de Embedding\": [\"Word2Vec (Frozen)\", \"Word2Vec (Fine-tune)\", \"Word2Vec (Scratch)\"],\n",
        "    \"Accuracy\": [0.499285, 0.502323, 0.492137],\n",
        "    \"Macro-F1\": [0.487054, 0.502254, 0.487125]\n",
        "}\n",
        "\n",
        "# Crear DataFrames\n",
        "df_finetune = pd.DataFrame(data_finetune)\n",
        "df_random = pd.DataFrame(data_random)\n",
        "df_word2vec = pd.DataFrame(data_word2vec)\n",
        "\n",
        "# Unir todos los DataFrames\n",
        "df_deep_learning = pd.concat([df_finetune, df_random, df_word2vec], ignore_index=True)\n",
        "\n",
        "# Redondear las métricas a 4 decimales para la presentación\n",
        "df_deep_learning_display = df_deep_learning.round(4)\n",
        "\n",
        "# Reordenar las columnas\n",
        "column_order = [\"Estrategia de Embedding\", \"Modelo\", \"Accuracy\", \"Macro-F1\"]\n",
        "df_deep_learning_display = df_deep_learning_display[column_order]\n",
        "\n",
        "# Imprimir la tabla\n",
        "print(\" Rendimiento de Modelos de Deep Learning (LSTM & GRU)\\n\")\n",
        "# Usar to_string para una salida de tabla limpia en consola\n",
        "print(df_deep_learning_display.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los modelos de Deep Learning muestran un comportamiento muy dependiente de la estrategia de embeddings utilizada y del tipo de arquitectura. En primer lugar, los modelos finetuneados, que ajustan los embeddings durante el entrenamiento, obtienen el mejor desempeño general. Tanto LSTM como GRU alcanzan accuracy y macro-F1 superiores a 0.51, con GRU ligeramente por encima de LSTM (0.5264 vs 0.5134 en accuracy). Esto sugiere que permitir que los embeddings aprendan junto con el modelo proporciona representaciones más ajustadas a la tarea y mejora la capacidad de generalización.\n",
        "\n",
        "En contraste, los modelos no finetuneados con embeddings aleatorios presentan un desempeño mucho más bajo, con accuracy alrededor de 0.39-0.40 y macro-F1 entre 0.33 y 0.35. Esto refleja que sin preentrenamiento ni ajuste, los modelos luchan por aprender representaciones significativas desde cero a partir de datos limitados. La ligera diferencia entre LSTM y GRU indica que la arquitectura por sí sola no es suficiente para compensar embeddings iniciales pobres.\n",
        "\n",
        "Cuando se usan embeddings preentrenados tipo Word2Vec, el desempeño se estabiliza entre 0.49 y 0.50 en accuracy. Mantener los embeddings congelados ofrece resultados razonables (0.4993 accuracy), mientras que permitir un finetune ligero mejora apenas a 0.5023, lo que indica que la adaptación incremental no aporta grandes ganancias en este caso. Entrenar embeddings desde cero (scratch) también genera resultados similares (0.4921 accuracy), mostrando que el preentrenamiento ayuda, pero no de manera dramática, frente a una arquitectura LSTM o GRU básica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4.3 Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultados Consolidados de Modelos de Representación de Texto\n",
            "\n",
            "Tipo de Embedding        Modelo/Técnica  Accuracy  F1 Score Clustering Score (Downstream)\n",
            "       Contextual Sentence Transformers    0.5395    0.5379                           NaN\n",
            "       Contextual                  BERT    0.3000    0.2505                           NaN\n",
            "      Tradicional                TF-IDF    0.7030    0.7023                           NaN\n",
            "      Tradicional    Bag-of-Words (BoW)    0.6467    0.6468                           NaN\n",
            "   No Contextual               Word2Vec       NaN       NaN                    184,242.41\n",
            "   No Contextual               FastText       NaN       NaN                    258,313.16\n"
          ]
        }
      ],
      "source": [
        "# Datos de los resultados de embeddings contextuales\n",
        "results_contextual = {\n",
        "    \"Modelo/Técnica\": [\"Sentence Transformers\", \"BERT\"],\n",
        "    \"Accuracy\": [0.5394924946390279, 0.3],\n",
        "    \"F1 Score\": [0.5379302986979321, 0.25047619047619046]\n",
        "}\n",
        "\n",
        "# Datos de los resultados de embeddings tradicionales (Shallow Learning)\n",
        "results_traditional = {\n",
        "    \"Modelo/Técnica\": [\"TF-IDF\", \"Bag-of-Words (BoW)\"],\n",
        "    \"Accuracy\": [0.703002, 0.646712],\n",
        "    \"F1 Score\": [0.702330, 0.646754]\n",
        "}\n",
        "\n",
        "# Datos de los resultados de embeddings no contextuales (Clustering Downstream)\n",
        "# Nota: Estas métricas son diferentes (ej. Inercia/Distorsión)\n",
        "results_clustering = {\n",
        "    \"Modelo/Técnica\": [\"Word2Vec\", \"FastText\"],\n",
        "    \"Clustering Score (Downstream)\": [184242.40625, 258313.15625]\n",
        "}\n",
        "\n",
        "# Crear DataFrames\n",
        "df_contextual = pd.DataFrame(results_contextual).assign(Tipo_Embedding=\"Contextual\")\n",
        "df_traditional = pd.DataFrame(results_traditional).assign(Tipo_Embedding=\"Tradicional\")\n",
        "df_clustering = pd.DataFrame(results_clustering).assign(Tipo_Embedding=\"No Contextual \")\n",
        "\n",
        "# Consolidar todos los DataFrames\n",
        "# Usamos pd.concat y rellenamos las columnas faltantes automáticamente con NaN\n",
        "df_results = pd.concat([df_contextual, df_traditional, df_clustering], ignore_index=True)\n",
        "\n",
        "# --- Formateo y limpieza ---\n",
        "\n",
        "# Redondear las métricas de clasificación a 4 decimales\n",
        "df_results[\"Accuracy\"] = df_results[\"Accuracy\"].round(4)\n",
        "df_results[\"F1 Score\"] = df_results[\"F1 Score\"].round(4)\n",
        "\n",
        "# Formatear el Clustering Score a 2 decimales para claridad y usar separador de miles\n",
        "df_results[\"Clustering Score (Downstream)\"] = df_results[\"Clustering Score (Downstream)\"].apply(\n",
        "    lambda x: f\"{x:,.2f}\" if pd.notna(x) else np.nan\n",
        ")\n",
        "\n",
        "# Reordenar las columnas para una mejor presentación\n",
        "column_order = [\"Tipo_Embedding\", \"Modelo/Técnica\", \"Accuracy\", \"F1 Score\", \"Clustering Score (Downstream)\"]\n",
        "df_results = df_results[column_order]\n",
        "\n",
        "# Renombrar la columna principal para la impresión\n",
        "df_results.rename(columns={\"Tipo_Embedding\": \"Tipo de Embedding\"}, inplace=True)\n",
        "\n",
        "# Imprimir la tabla\n",
        "print(\"Resultados Consolidados de Modelos de Representación de Texto\\n\")\n",
        "print(df_results.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los resultados muestran diferencias claras según el tipo de embedding utilizado. Los embeddings tradicionales (TF-IDF y Bag-of-Words) lograron el mejor desempeño en la tarea de clasificación de la variable bias, con accuracy de 0.7030 y 0.6467, y F1 scores de 0.7023 y 0.6468 respectivamente, lo que indica que estos enfoques aún son muy efectivos para tareas de machine learning sobre texto. En contraste, los embeddings contextuales (Sentence Transformers y BERT) obtuvieron valores más bajos en Accuracy y F1, siendo Sentence Transformers ligeramente superior a BERT (0.5395 vs 0.3000 en Accuracy), aunque ambos generaron vectores de documento útiles. Por último, los embeddings no-contextuales (Word2Vec y FastText) no se evaluaron directamente en clasificación, pero su desempeño en clustering muestra que Word2Vec produjo clusters más compactos (184,242) comparado con FastText (258,313), reflejando que sus representaciones capturan cierta estructura semántica, aunque no directamente utilizable para clasificación sin agregación de vectores por documento."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
