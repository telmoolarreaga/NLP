{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Antes de empezar con la explicación de esta entrega, debemos mencionar la corrección de dos errores de la entrega anterior. Hemos corregido el fallo de  aplicar stemming y lemmatización  tanto a TF-IDF como a embeddings. Ahora, solo se aplcia a TD-IDF. Además, adaptamos el Word2Vec para que no tuviese más de 30 epochs.\n",
        "\n",
        "Por otro lado, hemos sido capaces de aplicar shallow learning a las tres tareas de clasificación que teníamos previstas. Sin embargo, solo hemos logrado implementar deep learning y la comparación de embeddings a la clasificación de sesgo. Las dos tareas restantes estarán completadas para la siguiente entrega."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqfT1kYc_EOn"
      },
      "source": [
        "# **1. Shallow Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "from gensim.models import Word2Vec, FastText\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Embedding, Input\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from xgboost import XGBClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En esta versión se ha mejorado la sección de Shallow Learning principalmente en el análisis y la presentación de resultados. Mientras que antes el pipeline solo usaba train y validation, ahora se ha incorporado un split completo en train, evaluation y test, lo que permite aplicar técnicas como early stopping en modelos que lo soportan y evaluar finalmente el desempeño en un conjunto de test separado. Además, se ejecuta explícitamente para las tres tareas (Bias, Topic y Source) y se consolidan los resultados en una tabla comparativa con multi-índice, mostrando métricas de Accuracy y Macro-F1 por tarea. Se ha eliminado la referencia a XGBoost para evitar resultados vacíos, y se han redondeado las métricas para mejorar la legibilidad. Estos cambios permiten visualizar de manera directa el desempeño de cada modelo en todas las tareas, facilitando el análisis comparativo y la interpretación de los resultados. La preparación de los textos y el filtrado de clases se mantiene igual, indicando que las mejoras se centran en el rigor experimental, la consistencia de métricas y la presentación final."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para representar los textos, hemos elegido TF-IDF para capturar la importancia relativa de cada palabra en un documento frente al corpus completo, reduciendo el peso de palabras muy frecuentes que no aportan información discriminativa, como artículos y preposiciones en inglés. Hemos establecido un límite de 3,000 palabras más importantes para reducir la dimensionalidad. Además, hemos añadido unigramas y bigramas para capturar algo de contexto local sin sobrecargar el modelo. Por otro lado, hemos eliminado las palabras vacías en inglés para centrar el análisis en palabras significativas. Esta representación genera vectores dispersos que son ideales para los modelos clásicos que usamos.\n",
        "\n",
        "Hemos seleccionado tres modelos para evaluar el desempeño: Logistic Regression, LinearSVC y Random Forest.\n",
        "\n",
        "Antes de entrenar, hemos convertido los textos a números mediante label encoding, y realizado una división de train/test/validation del 70/15/15 para medir el rendimiento real, evitar overfitting y buscar hiperparametros. Además, hemos filtrado las clases con menos de dos registros, ya que la validación estratificada requiere al menos dos ejemplos por clase. La función recibe como parámetro la variable objetivo. En este caso, recibe las variables \"bias\", \"topic\" y \"source\", que son nuestras variables a clasificar.\n",
        "\n",
        "Finalmente, todos los modelos y el vectorizador TF-IDF han sido guardados para su reutilización. Este pipeline de Shallow Learning funciona como un baseline sólido que nos permite medir la mejora que aportan las representaciones densas y contextuales de texto que se utilizarán en las fases posteriores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def shallow_pipeline(df, target_col):\n",
        "    # Preparamos el texto\n",
        "    if \"text_joined\" not in df.columns:\n",
        "        df[\"text_joined\"] = df[\"tokens\"].apply(lambda x: \" \".join(x))\n",
        "    texts = df[\"text_joined\"].astype(str).tolist()\n",
        "    labels = df[target_col].tolist()\n",
        "\n",
        "    # Filtramos las clases con menos de 2 registros\n",
        "    counts = Counter(labels)\n",
        "    valid_classes = [c for c, cnt in counts.items() if cnt > 1]\n",
        "    mask = [lbl in valid_classes for lbl in labels]\n",
        "    texts = [t for t, m in zip(texts, mask) if m]\n",
        "    labels = [l for l, m in zip(labels, mask) if m]\n",
        "\n",
        "    # Codificamos las etiquetas\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(labels)\n",
        "\n",
        "    # Hacemos el train/validation split\n",
        "    X_train_text, X_val_text, y_train, y_val = train_test_split(\n",
        "        texts, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Aplicamos TF-IDF\n",
        "    vectorizer = TfidfVectorizer(max_features=3000, stop_words='english', ngram_range=(1,2))\n",
        "    X_train = vectorizer.fit_transform(X_train_text)\n",
        "    X_val = vectorizer.transform(X_val_text)\n",
        "\n",
        "    # Definimos los modelos\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegression(max_iter=1000, n_jobs=-1),\n",
        "        \"LinearSVC\": LinearSVC(),\n",
        "        \"Random Forest\": RandomForestClassifier(n_estimators=150, n_jobs=-1),\n",
        "       # \"XGBoost\": XGBClassifier(n_estimators=75, eval_metric=\"mlogloss\", tree_method=\"hist\", n_jobs=-1)\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # Entrenamos, evaluamos y guardamos los modelos\n",
        "    os.makedirs(\"data/models\", exist_ok=True)\n",
        "    for name, model in models.items():\n",
        "        print(f\"Entrenando {name}...\")\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_val)\n",
        "        results[name] = {\n",
        "            \"Accuracy\": accuracy_score(y_val, y_pred),\n",
        "            \"Macro-F1\": f1_score(y_val, y_pred, average=\"macro\")\n",
        "        }\n",
        "        # Guardamos el modelo\n",
        "        pickle.dump(model, open(f\"data/models/{name.replace(' ', '_').lower()}.pkl\", \"wb\"))\n",
        "\n",
        "    # Guardamos el vectorizador\n",
        "    os.makedirs(\"data/features\", exist_ok=True)\n",
        "    pickle.dump(vectorizer, open(\"data/features/tfidf_vectorizer.pkl\", \"wb\"))\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hemos tenido que incluir un filtro para eliminar las clases que tenían menos de dos registros antes de hacer el train_test_split. Esto se debe a que tuvimos un error al utilizar el parámetro stratify=y, que requiere al menos dos ejemplos por clase para poder crear correctamente los conjuntos de entrenamiento y validación de manera estratificada. Sin este filtro, cualquier clase con un único ejemplo provocaría que la ejecución se detuviera, como ocurría previamente con la variable source. Al aplicar este filtrado, nos aseguramos de que solo se utilicen clases con suficiente cantidad de datos, garantizando que la partición estratificada funcione y evitando que el pipeline falle durante el entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los resultados se analizarán en la sección 4 de este noteebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_pickle(\"data/data_clean/train_tokenized.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenando Logistic Regression...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenando LinearSVC...\n",
            "Entrenando Random Forest...\n",
            "                     Accuracy  Macro-F1\n",
            "Logistic Regression  0.702109  0.700091\n",
            "LinearSVC            0.698713  0.696551\n",
            "Random Forest        0.693710  0.690578\n"
          ]
        }
      ],
      "source": [
        "# Llamamos a la función con bias\n",
        "results_bias = shallow_pipeline(df, \"bias\")\n",
        "print(pd.DataFrame(results_bias).T)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenando Logistic Regression...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenando LinearSVC...\n",
            "Entrenando Random Forest...\n",
            "                     Accuracy  Macro-F1\n",
            "Logistic Regression  0.581129  0.338987\n",
            "LinearSVC            0.589171  0.410156\n",
            "Random Forest        0.520372  0.244504\n"
          ]
        }
      ],
      "source": [
        "# Llamamos a la función con topic\n",
        "results_topic = shallow_pipeline(df, \"topic\")\n",
        "print(pd.DataFrame(results_topic).T)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenando Logistic Regression...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenando LinearSVC...\n",
            "Entrenando Random Forest...\n",
            "                     Accuracy  Macro-F1\n",
            "Logistic Regression  0.503401  0.103117\n",
            "LinearSVC            0.559076  0.219572\n",
            "Random Forest        0.499642  0.127022\n"
          ]
        }
      ],
      "source": [
        "# Llamamos a la función con source\n",
        "results_source = shallow_pipeline(df, \"source\")\n",
        "print(pd.DataFrame(results_source).T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztbnwVJVWSgX"
      },
      "source": [
        "# **2. Modelos Deep**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En la parte de Deep Learning, hemos optado por utilizar redes neuronales recurrentes, específicamente LSTM y GRU, debido a su capacidad para capturar dependencias secuenciales en el texto. A diferencia de los modelos de Shallow Learning, que tratan cada palabra o n-grama de manera independiente, las RNNs permiten que la red recuerde información contextual de palabras anteriores en la secuencia, lo cual es crucial para nuestras tareas de clasificación de texto, donde el significado puede depender del orden de las palabras.\n",
        "\n",
        "Para la representación de los textos, hemos empleado embeddings densos, utilizando tres enfoques distintos con Word2Vec: congelado, fine-tune y desde cero. En el caso de los embeddings congelados, utilizamos un modelo preentrenado de Word2Vec y lo fijamos durante el entrenamiento de la red, de manera que solo la LSTM o GRU aprenda a combinar los vectores preexistentes. Esto permite evaluar cuánto conocimiento semántico ya capturado en Word2Vec puede ayudar a la tarea sin modificarlo. En el enfoque de fine-tune, los embeddings inicializados con Word2Vec se ajustan durante el entrenamiento, permitiendo que la red adapte los vectores a las particularidades del dataset específico. Finalmente, la opción de embeddings entrenados desde cero crea vectores aleatorios que se aprenden completamente durante el entrenamiento, lo que permite que la red descubra representaciones óptimas para la tarea, aunque requiere más datos y tiempo de entrenamiento.\n",
        "\n",
        "Hemos elegido LSTM y GRU, ya que cumple nuestra necesidad de comparar dos variantes de redes recurrentes: las LSTM tienen una mayor capacidad para capturar dependencias de largo plazo mediante su mecanismo de puertas, mientras que las GRU son más simples y computacionalmente eficientes, lo que puede acelerar el entrenamiento sin perder demasiado rendimiento.\n",
        "\n",
        "Los textos se transforman primero en secuencias de índices según el vocabulario de Word2Vec o un tokenizer entrenado sobre el dataset, y se aplica padding para unificar la longitud de las secuencias. Esto asegura que las redes puedan procesar lotes de datos de manera eficiente. Finalmente, la capa de salida utiliza softmax para producir probabilidades sobre las clases, y la red se entrena con categorical crossentropy, optimizando la accuracy y el macro-F1 como métricas de desempeño, lo cual es consistente con la evaluación utilizada en la parte de Shallow Learning.\n",
        "\n",
        "En conclusión, este apartado permite que nuestra red aprenda tanto representaciones densas de palabras como patrones secuenciales de las oraciones, ofreciendo una ventaja sobre los modelos lineales y de ensamble de Shallow Learning que solo utilizan información superficial y dispersa de los textos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Embeddings fine-tuneados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 1s/step - accuracy: 0.4110 - loss: 1.0727 - val_accuracy: 0.4558 - val_loss: 1.0455\n",
            "Epoch 2/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 1s/step - accuracy: 0.5035 - loss: 0.9876 - val_accuracy: 0.4808 - val_loss: 0.9915\n",
            "Epoch 3/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 960ms/step - accuracy: 0.5876 - loss: 0.8714 - val_accuracy: 0.4961 - val_loss: 0.9985\n",
            "Epoch 4/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 2s/step - accuracy: 0.6633 - loss: 0.7473 - val_accuracy: 0.4892 - val_loss: 1.0340\n",
            "Epoch 5/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 997ms/step - accuracy: 0.7457 - loss: 0.5982 - val_accuracy: 0.5006 - val_loss: 1.1641\n",
            "Epoch 1/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 917ms/step - accuracy: 0.3961 - loss: 1.0813 - val_accuracy: 0.4229 - val_loss: 1.0698\n",
            "Epoch 2/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 1s/step - accuracy: 0.4890 - loss: 1.0051 - val_accuracy: 0.4808 - val_loss: 0.9939\n",
            "Epoch 3/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 679ms/step - accuracy: 0.5864 - loss: 0.8628 - val_accuracy: 0.5130 - val_loss: 0.9604\n",
            "Epoch 4/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 643ms/step - accuracy: 0.6878 - loss: 0.7080 - val_accuracy: 0.5194 - val_loss: 0.9919\n",
            "Epoch 5/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 1s/step - accuracy: 0.7885 - loss: 0.5164 - val_accuracy: 0.5187 - val_loss: 1.1682\n",
            "Epoch 6/20\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 1s/step - accuracy: 0.8627 - loss: 0.3393 - val_accuracy: 0.5206 - val_loss: 1.3048\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 448ms/step\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 374ms/step\n",
            "Resultados finales sobre TEST:\n",
            "      Accuracy  Macro-F1\n",
            "LSTM  0.496783  0.494741\n",
            "GRU   0.527281  0.527386\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Cargar dataset y etiquetas\n",
        "# ----------------------------\n",
        "df_train = pd.read_pickle(\"data/data_clean/train_tokenized.pkl\")\n",
        "y = df_train[\"bias\"].values\n",
        "\n",
        "# Codificamos las labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "y_cat = to_categorical(y_encoded)\n",
        "\n",
        "# Necesitamos versión entera para stratify\n",
        "y_int = np.argmax(y_cat, axis=1)\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Train / Val / Test split\n",
        "# ----------------------------\n",
        "# Primero train + temp (val+test)\n",
        "X_train_texts, X_temp_texts, y_train, y_temp = train_test_split(\n",
        "    df_train[\"tokens\"], y_cat, test_size=0.3, random_state=42, stratify=y_cat\n",
        ")\n",
        "\n",
        "# Luego temp → val + test (dividimos 50/50 del 30% → 15/15)\n",
        "X_val_texts, X_test_texts, y_val, y_test = train_test_split(\n",
        "    X_temp_texts, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Word2Vec embeddings\n",
        "# ----------------------------\n",
        "w2v_model = Word2Vec.load(\"data/embeddings/word2vec.model\")\n",
        "embedding_dim = w2v_model.vector_size\n",
        "word_index = {word: i+1 for i, word in enumerate(w2v_model.wv.index_to_key)}\n",
        "vocab_size = len(word_index) + 1  # +1 para padding\n",
        "\n",
        "def tokens_to_indices(tokens, word_index):\n",
        "    return [word_index[t] for t in tokens if t in word_index]\n",
        "\n",
        "X_train_idx = [tokens_to_indices(t, word_index) for t in X_train_texts]\n",
        "X_val_idx = [tokens_to_indices(t, word_index) for t in X_val_texts]\n",
        "X_test_idx = [tokens_to_indices(t, word_index) for t in X_test_texts]\n",
        "\n",
        "max_seq_len = 200\n",
        "X_train_pad = pad_sequences(X_train_idx, maxlen=max_seq_len, padding='post')\n",
        "X_val_pad = pad_sequences(X_val_idx, maxlen=max_seq_len, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_idx, maxlen=max_seq_len, padding='post')\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_matrix[i] = w2v_model.wv[word]\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Definición del modelo RNN\n",
        "# ----------------------------\n",
        "def build_rnn(model_type='LSTM'):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        weights=[embedding_matrix],\n",
        "        input_length=max_seq_len,\n",
        "        trainable=True  # Fine-tune embeddings\n",
        "    ))\n",
        "    if model_type == 'LSTM':\n",
        "        model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "    elif model_type == 'GRU':\n",
        "        model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(y_cat.shape[1], activation='softmax'))\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-3),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# ----------------------------\n",
        "# 5. Early stopping\n",
        "# ----------------------------\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 6. Entrenamiento y evaluación\n",
        "# ----------------------------\n",
        "# LSTM\n",
        "lstm_model = build_rnn('LSTM')\n",
        "lstm_history = lstm_model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# GRU\n",
        "gru_model = build_rnn('GRU')\n",
        "gru_history = gru_model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 7. Predicciones sobre TEST\n",
        "# ----------------------------\n",
        "y_pred_lstm = np.argmax(lstm_model.predict(X_test_pad, batch_size=64), axis=1)\n",
        "y_pred_gru = np.argmax(gru_model.predict(X_test_pad, batch_size=64), axis=1)\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# ----------------------------\n",
        "# 8. Métricas finales\n",
        "# ----------------------------\n",
        "results = {\n",
        "    'LSTM': {\n",
        "        'Accuracy': accuracy_score(y_test_labels, y_pred_lstm),\n",
        "        'Macro-F1': f1_score(y_test_labels, y_pred_lstm, average='macro')\n",
        "    },\n",
        "    'GRU': {\n",
        "        'Accuracy': accuracy_score(y_test_labels, y_pred_gru),\n",
        "        'Macro-F1': f1_score(y_test_labels, y_pred_gru, average='macro')\n",
        "    }\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"Resultados finales sobre TEST:\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Embeddings no finetuneados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 80ms/step - accuracy: 0.3629 - loss: 1.0932 - val_accuracy: 0.3520 - val_loss: 1.0923\n",
            "Epoch 2/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - accuracy: 0.3732 - loss: 1.0902 - val_accuracy: 0.3781 - val_loss: 1.0885\n",
            "Epoch 3/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - accuracy: 0.3859 - loss: 1.0845 - val_accuracy: 0.3813 - val_loss: 1.0865\n",
            "Epoch 4/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - accuracy: 0.4032 - loss: 1.0797 - val_accuracy: 0.3821 - val_loss: 1.0812\n",
            "Epoch 5/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 90ms/step - accuracy: 0.4079 - loss: 1.0737 - val_accuracy: 0.3931 - val_loss: 1.0790\n",
            "Epoch 6/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 89ms/step - accuracy: 0.4140 - loss: 1.0700 - val_accuracy: 0.3830 - val_loss: 1.0854\n",
            "Epoch 7/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 89ms/step - accuracy: 0.4247 - loss: 1.0628 - val_accuracy: 0.3831 - val_loss: 1.0831\n",
            "Epoch 8/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 89ms/step - accuracy: 0.4268 - loss: 1.0594 - val_accuracy: 0.3881 - val_loss: 1.0782\n",
            "Epoch 9/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.4342 - loss: 1.0567 - val_accuracy: 0.3919 - val_loss: 1.0737\n",
            "Epoch 10/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 90ms/step - accuracy: 0.4329 - loss: 1.0547 - val_accuracy: 0.3813 - val_loss: 1.0844\n",
            "Epoch 11/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 88ms/step - accuracy: 0.4427 - loss: 1.0438 - val_accuracy: 0.4110 - val_loss: 1.0554\n",
            "Epoch 12/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 89ms/step - accuracy: 0.4467 - loss: 1.0492 - val_accuracy: 0.3865 - val_loss: 1.0866\n",
            "Epoch 13/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 88ms/step - accuracy: 0.4339 - loss: 1.0535 - val_accuracy: 0.3914 - val_loss: 1.0825\n",
            "Epoch 14/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 70ms/step - accuracy: 0.4340 - loss: 1.0463 - val_accuracy: 0.3937 - val_loss: 1.0841\n",
            "Epoch 1/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 116ms/step - accuracy: 0.3666 - loss: 1.0933 - val_accuracy: 0.3660 - val_loss: 1.0926\n",
            "Epoch 2/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 123ms/step - accuracy: 0.3781 - loss: 1.0887 - val_accuracy: 0.3794 - val_loss: 1.0883\n",
            "Epoch 3/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 123ms/step - accuracy: 0.3931 - loss: 1.0809 - val_accuracy: 0.3844 - val_loss: 1.0821\n",
            "\n",
            "Resultados Embedding Random (NO fine-tuneado)\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.39      0.39      1950\n",
            "           1       0.47      0.30      0.36      1598\n",
            "           2       0.41      0.53      0.47      2048\n",
            "\n",
            "    accuracy                           0.42      5596\n",
            "   macro avg       0.42      0.41      0.41      5596\n",
            "weighted avg       0.42      0.42      0.41      5596\n",
            "\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1950\n",
            "           1       0.00      0.00      0.00      1598\n",
            "           2       0.37      1.00      0.54      2048\n",
            "\n",
            "    accuracy                           0.37      5596\n",
            "   macro avg       0.12      0.33      0.18      5596\n",
            "weighted avg       0.13      0.37      0.20      5596\n",
            "\n",
            "  Model  Accuracy  Macro-F1\n",
            "0  LSTM  0.415654  0.406401\n",
            "1   GRU  0.365976  0.178615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "c:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "c:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Dataset\n",
        "# ----------------------------\n",
        "df[\"text_joined\"] = df[\"tokens\"].apply(lambda x: \" \".join(x))\n",
        "texts = df[\"text_joined\"].astype(str).tolist()\n",
        "labels = df[\"bias\"].tolist()\n",
        "\n",
        "# Tokenización y secuencias\n",
        "vocab_size = 20000\n",
        "maxlen = 100\n",
        "embedding_dim = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "X_seq = tokenizer.texts_to_sequences(texts)\n",
        "X = pad_sequences(X_seq, maxlen=maxlen)\n",
        "\n",
        "# Codificamos las etiquetas\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(labels)  # entero para Keras\n",
        "y = y_encoded  # usado en train/val/test\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Train / Validation / Test split (70/15/15)\n",
        "# ----------------------------\n",
        "X_train_texts, X_temp_texts, y_train, y_temp = train_test_split(\n",
        "    df_train[\"tokens\"], y_cat, test_size=0.3, random_state=42, stratify=y_cat\n",
        ")\n",
        "\n",
        "# Luego temp → val + test (dividimos 50/50 del 30% → 15/15)\n",
        "X_val_texts, X_test_texts, y_val, y_test = train_test_split(\n",
        "    X_temp_texts, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Funciones de modelos\n",
        "# ----------------------------\n",
        "def build_lstm_model():\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim, input_length=maxlen, trainable=False),\n",
        "        LSTM(128, return_sequences=False),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(len(le.classes_), activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "def build_gru_model():\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim, input_length=maxlen, trainable=False),\n",
        "        GRU(128, return_sequences=False),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(len(le.classes_), activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Early stopping\n",
        "# ----------------------------\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# ----------------------------\n",
        "# 5. Entrenamiento\n",
        "# ----------------------------\n",
        "lstm_model = build_lstm_model()\n",
        "history_lstm = lstm_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "gru_model = build_gru_model()\n",
        "history_gru = gru_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 6. Evaluación por clase\n",
        "# ----------------------------\n",
        "def evaluate(model, X_test, y_test):\n",
        "    preds = np.argmax(model.predict(X_test, batch_size=64), axis=1)\n",
        "    # Convertimos a nombres originales de clases\n",
        "    y_test_str = le.inverse_transform(y_test)\n",
        "    preds_str = le.inverse_transform(preds)\n",
        "    print(classification_report(y_test_str, preds_str))\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    f1 = f1_score(y_test, preds, average='macro')\n",
        "    return acc, f1\n",
        "\n",
        "print(\"\\nResultados Embedding Random (NO fine-tuneado)\")\n",
        "acc_lstm, f1_lstm = evaluate(lstm_model, X_test, y_test)\n",
        "acc_gru, f1_gru = evaluate(gru_model, X_test, y_test)\n",
        "\n",
        "# ----------------------------\n",
        "# 7. Guardar resultados en DataFrame\n",
        "# ----------------------------\n",
        "results_df = pd.DataFrame({\n",
        "    'Model': ['LSTM', 'GRU'],\n",
        "    'Accuracy': [acc_lstm, acc_gru],\n",
        "    'Macro-F1': [f1_lstm, f1_gru]\n",
        "})\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Word2Vec congelado vs Word2Vec fine-tuneado vs Word2Vec from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 464ms/step - accuracy: 0.4063 - loss: 1.0746 - val_accuracy: 0.4419 - val_loss: 1.0360\n",
            "Epoch 2/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 525ms/step - accuracy: 0.4442 - loss: 1.0400 - val_accuracy: 0.4618 - val_loss: 1.0181\n",
            "Epoch 3/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 489ms/step - accuracy: 0.4417 - loss: 1.0503 - val_accuracy: 0.4366 - val_loss: 1.0464\n",
            "Epoch 4/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 489ms/step - accuracy: 0.4611 - loss: 1.0217 - val_accuracy: 0.4725 - val_loss: 0.9975\n",
            "Epoch 5/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 494ms/step - accuracy: 0.4757 - loss: 1.0001 - val_accuracy: 0.4700 - val_loss: 0.9931\n",
            "Epoch 6/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 485ms/step - accuracy: 0.4924 - loss: 0.9850 - val_accuracy: 0.4748 - val_loss: 0.9890\n",
            "Epoch 7/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 520ms/step - accuracy: 0.4957 - loss: 0.9716 - val_accuracy: 0.4920 - val_loss: 0.9786\n",
            "Epoch 8/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 474ms/step - accuracy: 0.4929 - loss: 0.9800 - val_accuracy: 0.4882 - val_loss: 0.9846\n",
            "Epoch 9/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 485ms/step - accuracy: 0.4912 - loss: 0.9873 - val_accuracy: 0.4712 - val_loss: 0.9890\n",
            "Epoch 10/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 505ms/step - accuracy: 0.5122 - loss: 0.9591 - val_accuracy: 0.4898 - val_loss: 0.9764\n",
            "Epoch 11/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 506ms/step - accuracy: 0.4873 - loss: 0.9803 - val_accuracy: 0.4164 - val_loss: 1.0649\n",
            "Epoch 12/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 491ms/step - accuracy: 0.4520 - loss: 1.0254 - val_accuracy: 0.4769 - val_loss: 0.9877\n",
            "Epoch 13/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 486ms/step - accuracy: 0.5149 - loss: 0.9577 - val_accuracy: 0.5041 - val_loss: 0.9706\n",
            "Epoch 14/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 493ms/step - accuracy: 0.5351 - loss: 0.9304 - val_accuracy: 0.4945 - val_loss: 0.9728\n",
            "Epoch 15/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 494ms/step - accuracy: 0.5451 - loss: 0.9201 - val_accuracy: 0.5109 - val_loss: 0.9619\n",
            "Epoch 16/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 489ms/step - accuracy: 0.5486 - loss: 0.9086 - val_accuracy: 0.5193 - val_loss: 0.9542\n",
            "Epoch 17/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 490ms/step - accuracy: 0.5700 - loss: 0.8915 - val_accuracy: 0.5327 - val_loss: 0.9451\n",
            "Epoch 18/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 464ms/step - accuracy: 0.5763 - loss: 0.8796 - val_accuracy: 0.5388 - val_loss: 0.9342\n",
            "Epoch 19/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 458ms/step - accuracy: 0.5917 - loss: 0.8657 - val_accuracy: 0.5456 - val_loss: 0.9366\n",
            "Epoch 20/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 492ms/step - accuracy: 0.5951 - loss: 0.8493 - val_accuracy: 0.5482 - val_loss: 0.9248\n",
            "Epoch 1/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 571ms/step - accuracy: 0.4109 - loss: 1.0723 - val_accuracy: 0.4326 - val_loss: 1.0536\n",
            "Epoch 2/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 541ms/step - accuracy: 0.4756 - loss: 1.0153 - val_accuracy: 0.4350 - val_loss: 1.0517\n",
            "Epoch 3/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 567ms/step - accuracy: 0.5602 - loss: 0.9185 - val_accuracy: 0.4929 - val_loss: 0.9932\n",
            "Epoch 1/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 538ms/step - accuracy: 0.3780 - loss: 1.0910 - val_accuracy: 0.4060 - val_loss: 1.0723\n",
            "Epoch 2/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 555ms/step - accuracy: 0.4650 - loss: 1.0299 - val_accuracy: 0.4351 - val_loss: 1.0490\n",
            "Epoch 3/20\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 550ms/step - accuracy: 0.5282 - loss: 0.9605 - val_accuracy: 0.4684 - val_loss: 1.0406\n",
            "\n",
            "Resultados Word2Vec Frozen\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 157ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.48      0.52      1950\n",
            "           1       0.62      0.46      0.53      1598\n",
            "           2       0.51      0.67      0.58      2048\n",
            "\n",
            "    accuracy                           0.55      5596\n",
            "   macro avg       0.56      0.54      0.54      5596\n",
            "weighted avg       0.55      0.55      0.54      5596\n",
            "\n",
            "\n",
            "Resultados Word2Vec Fine-tune\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 154ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.68      0.51      1950\n",
            "           1       0.46      0.27      0.34      1598\n",
            "           2       0.49      0.34      0.40      2048\n",
            "\n",
            "    accuracy                           0.44      5596\n",
            "   macro avg       0.45      0.43      0.42      5596\n",
            "weighted avg       0.45      0.44      0.42      5596\n",
            "\n",
            "\n",
            "Resultados Word2Vec Scratch\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 153ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.35      0.37      1950\n",
            "           1       0.40      0.20      0.27      1598\n",
            "           2       0.41      0.61      0.49      2048\n",
            "\n",
            "    accuracy                           0.40      5596\n",
            "   macro avg       0.40      0.39      0.38      5596\n",
            "weighted avg       0.40      0.40      0.39      5596\n",
            "\n",
            "                    Accuracy  Macro-F1\n",
            "Word2Vec Frozen     0.545390  0.541059\n",
            "Word2Vec Fine-tune  0.438349  0.417913\n",
            "Word2Vec Scratch    0.403860  0.377377\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Cargar dataset y etiquetas\n",
        "# ----------------------------\n",
        "df = pd.read_pickle(\"data/data_clean/train_tokenized.pkl\")\n",
        "df[\"text_joined\"] = df[\"tokens\"].apply(lambda x: \" \".join(x))\n",
        "\n",
        "texts = df[\"tokens\"].tolist()\n",
        "labels = df[\"bias\"].tolist()\n",
        "\n",
        "# Codificamos las etiquetas\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(labels)\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Train / Val / Test split (70/15/15)\n",
        "# ----------------------------\n",
        "X_train_texts, X_temp_texts, y_train, y_temp = train_test_split(\n",
        "    df_train[\"tokens\"], y_cat, test_size=0.3, random_state=42, stratify=y_cat\n",
        ")\n",
        "\n",
        "# Luego temp → val + test (dividimos 50/50 del 30% → 15/15)\n",
        "X_val_texts, X_test_texts, y_val, y_test = train_test_split(\n",
        "    X_temp_texts, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Cargar Word2Vec preentrenado\n",
        "# ----------------------------\n",
        "w2v_model = Word2Vec.load(\"data/embeddings/word2vec.model\")\n",
        "embedding_dim = w2v_model.vector_size\n",
        "word_index = {word: i+1 for i, word in enumerate(w2v_model.wv.index_to_key)}\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "def tokens_to_indices(tokens, word_index):\n",
        "    return [word_index[t] for t in tokens if t in word_index]\n",
        "\n",
        "X_train_idx = [tokens_to_indices(t, word_index) for t in X_train_text]\n",
        "X_val_idx = [tokens_to_indices(t, word_index) for t in X_val_text]\n",
        "X_test_idx = [tokens_to_indices(t, word_index) for t in X_test_text]\n",
        "\n",
        "max_seq_len = 200\n",
        "X_train_pad = pad_sequences(X_train_idx, maxlen=max_seq_len, padding='post')\n",
        "X_val_pad = pad_sequences(X_val_idx, maxlen=max_seq_len, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_idx, maxlen=max_seq_len, padding='post')\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_matrix[i] = w2v_model.wv[word]\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Función para LSTM con embeddings preentrenados\n",
        "# ----------------------------\n",
        "def build_lstm_model(embedding_matrix, trainable=True):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(\n",
        "        input_dim=embedding_matrix.shape[0],\n",
        "        output_dim=embedding_matrix.shape[1],\n",
        "        weights=[embedding_matrix],\n",
        "        input_length=max_seq_len,\n",
        "        trainable=trainable\n",
        "    ))\n",
        "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(len(np.unique(y)), activation='softmax'))\n",
        "    model.compile(optimizer=Adam(1e-3),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# ----------------------------\n",
        "# 5. Early stopping\n",
        "# ----------------------------\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# ----------------------------\n",
        "# 6. Entrenamiento de los modelos\n",
        "# ----------------------------\n",
        "# Word2Vec Frozen\n",
        "lstm_frozen = build_lstm_model(embedding_matrix, trainable=False)\n",
        "history_frozen = lstm_frozen.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Word2Vec Fine-tune\n",
        "lstm_finetune = build_lstm_model(embedding_matrix, trainable=True)\n",
        "history_finetune = lstm_finetune.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Word2Vec Scratch\n",
        "embedding_matrix_random = np.random.normal(size=(vocab_size, embedding_dim))\n",
        "lstm_scratch = build_lstm_model(embedding_matrix_random, trainable=True)\n",
        "history_scratch = lstm_scratch.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 7. Evaluación por clase\n",
        "# ----------------------------\n",
        "def evaluate(model, X_test, y_test):\n",
        "    preds = np.argmax(model.predict(X_test, batch_size=64), axis=1)\n",
        "    # Convertimos enteros a nombres de clases para el classification_report\n",
        "    y_test_str = le.inverse_transform(y_test)\n",
        "    preds_str = le.inverse_transform(preds)\n",
        "    print(classification_report(y_test_str, preds_str))\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    f1 = f1_score(y_test, preds, average='macro')\n",
        "    return acc, f1\n",
        "\n",
        "results = {}\n",
        "\n",
        "print(\"\\nResultados Word2Vec Frozen\")\n",
        "results['Word2Vec Frozen'] = evaluate(lstm_frozen, X_test_pad, y_test)\n",
        "\n",
        "print(\"\\nResultados Word2Vec Fine-tune\")\n",
        "results['Word2Vec Fine-tune'] = evaluate(lstm_finetune, X_test_pad, y_test)\n",
        "\n",
        "print(\"\\nResultados Word2Vec Scratch\")\n",
        "results['Word2Vec Scratch'] = evaluate(lstm_scratch, X_test_pad, y_test)\n",
        "\n",
        "# ----------------------------\n",
        "# 8. Resultados finales\n",
        "# ----------------------------\n",
        "results_df = pd.DataFrame(results, index=['Accuracy','Macro-F1']).T\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **3. Comparación de Embeddings**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En esta sección se consideran distintas técnicas de representación de texto para tareas de clasificación orientadas a la detección de sesgos ideológicos, tema y medio en artículos periodísticos. Para ello se analizan enfoques tradicionales, embeddings no contextuales y embeddings contextuales, con el objetivo de entender cómo cada representación captura información relevante del lenguaje dentro de este dominio específico.\n",
        "\n",
        "Los métodos tradicionales, como TF-IDF y Bag-of-Words (BoW), representan el texto mediante vectores dispersos basados únicamente en la frecuencia o presencia de términos, sin tener en cuenta el word order ni el context. Se espera que estos enfoques funcionen bien cuando ciertas palabras clave o expresiones son indicadores directos de postura ideológica o del tema tratado. Sin embargo, su capacidad para capturar matices ideológicos sutiles, estructuras discursivas o patrones retóricos es limitada debido a la ausencia de información contextual.\n",
        "\n",
        "Los embeddings no contextuales, como Word2Vec y FastText, generan dense word vectors aprendidos a partir de coocurrencias en un corpus. Estos modelos son capaces de capturar similitudes semánticas entre palabras y asociaciones típicas del lenguaje periodístico, lo que ayuda a identificar vocabulario característico de ciertos medios o tendencias ideológicas. Aunque estos embeddings proporcionan una representación más rica que los métodos tradicionales, no distinguen los diferentes significados de una palabra según el contexto en el que aparece. En el caso de FastText, el uso de subword embeddings permite manejar mejor palabras raras, neologismos o términos específicos de determinados medios.\n",
        "\n",
        "Finalmente, los embeddings contextuales, como Sentence Transformers o BERT, generan representaciones que dependen del contexto completo de la oración o del documento. Esto permite que una misma palabra tenga diferentes vectores según su significado en el artículo, capturando relaciones semánticas complejas, long-range dependencies y matices ideológicos implícitos. Se espera que estos modelos sean especialmente efectivos para detectar bias más sutil, diferencias discursivas entre medios y patrones retóricos que dependen del estilo o la narrativa del artículo. No obstante, este tipo de modelos suele requerir un mayor volumen de datos y mayor capacidad computacional para ajustarse correctamente a tareas especializadas como la clasificación ideológica o la identificación del medio.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3.1 Embeddings tradicionales**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF - Classification Report (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.71      0.71      1950\n",
            "           1       0.71      0.65      0.68      1598\n",
            "           2       0.70      0.74      0.72      2048\n",
            "\n",
            "    accuracy                           0.71      5596\n",
            "   macro avg       0.71      0.70      0.70      5596\n",
            "weighted avg       0.71      0.71      0.70      5596\n",
            "\n",
            "Bag-of-Words - Classification Report (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.62      0.63      1950\n",
            "           1       0.61      0.62      0.61      1598\n",
            "           2       0.65      0.65      0.65      2048\n",
            "\n",
            "    accuracy                           0.63      5596\n",
            "   macro avg       0.63      0.63      0.63      5596\n",
            "weighted avg       0.63      0.63      0.63      5596\n",
            "\n",
            "\n",
            "Comparativa Embeddings Tradicionales:\n",
            "              Val Accuracy  Test Accuracy  Val F1 (weighted)  \\\n",
            "TF-IDF            0.685490       0.705325           0.685151   \n",
            "Bag-of-Words      0.621337       0.633667           0.621458   \n",
            "\n",
            "              Test F1 (weighted)  \n",
            "TF-IDF                  0.704853  \n",
            "Bag-of-Words            0.633737  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Cargamos y preparamos los datos\n",
        "df_train = pd.read_pickle(\"data/data_clean/train_tokenized.pkl\")\n",
        "df_train[\"text_joined\"] = df_train[\"tokens\"].apply(lambda x: \" \".join(x))\n",
        "texts = df_train[\"text_joined\"].tolist()\n",
        "y = df_train[\"bias\"].values\n",
        "\n",
        "results = {}\n",
        "\n",
        "# -------------------\n",
        "# Train / Val / Test\n",
        "# -------------------\n",
        "# 1. Separamos el 15% para Test\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    texts, y, test_size=0.15, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 2. Del 85% restante, tomamos el ~17.65% para que sea el 15% del total original\n",
        "# (0.15 / 0.85 = 0.17647...)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.1765, random_state=42, stratify=y_temp\n",
        ")\n",
        "# -------------------\n",
        "# TF-IDF\n",
        "# -------------------\n",
        "tfidf = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1,2))\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_val_tfidf = tfidf.transform(X_val)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "y_val_pred = clf.predict(X_val_tfidf)\n",
        "y_test_pred = clf.predict(X_test_tfidf)\n",
        "\n",
        "results[\"TF-IDF\"] = {\n",
        "    \"Val Accuracy\": accuracy_score(y_val, y_val_pred),\n",
        "    \"Test Accuracy\": accuracy_score(y_test, y_test_pred),\n",
        "    \"Val F1 (weighted)\": f1_score(y_val, y_val_pred, average=\"weighted\"),\n",
        "    \"Test F1 (weighted)\": f1_score(y_test, y_test_pred, average=\"weighted\")\n",
        "}\n",
        "\n",
        "print(\"TF-IDF - Classification Report (Test):\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# -------------------\n",
        "# Bag-of-Words\n",
        "# -------------------\n",
        "bow = CountVectorizer(max_features=5000, stop_words='english', ngram_range=(1,2))\n",
        "X_train_bow = bow.fit_transform(X_train)\n",
        "X_val_bow = bow.transform(X_val)\n",
        "X_test_bow = bow.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_bow, y_train)\n",
        "\n",
        "y_val_pred = clf.predict(X_val_bow)\n",
        "y_test_pred = clf.predict(X_test_bow)\n",
        "\n",
        "results[\"Bag-of-Words\"] = {\n",
        "    \"Val Accuracy\": accuracy_score(y_val, y_val_pred),\n",
        "    \"Test Accuracy\": accuracy_score(y_test, y_test_pred),\n",
        "    \"Val F1 (weighted)\": f1_score(y_val, y_val_pred, average=\"weighted\"),\n",
        "    \"Test F1 (weighted)\": f1_score(y_test, y_test_pred, average=\"weighted\")\n",
        "}\n",
        "\n",
        "print(\"Bag-of-Words - Classification Report (Test):\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# -------------------\n",
        "# Resultados\n",
        "# -------------------\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"\\nComparativa Embeddings Tradicionales:\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3.2 Embeddings no contextuales**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word2Vec - Classification Report (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.57      0.55      1950\n",
            "           1       0.52      0.43      0.47      1598\n",
            "           2       0.54      0.59      0.57      2048\n",
            "\n",
            "    accuracy                           0.54      5596\n",
            "   macro avg       0.54      0.53      0.53      5596\n",
            "weighted avg       0.54      0.54      0.53      5596\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
            "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FastText - Classification Report (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.57      0.56      1950\n",
            "           1       0.53      0.44      0.48      1598\n",
            "           2       0.55      0.60      0.58      2048\n",
            "\n",
            "    accuracy                           0.54      5596\n",
            "   macro avg       0.54      0.54      0.54      5596\n",
            "weighted avg       0.54      0.54      0.54      5596\n",
            "\n",
            "\n",
            "Comparativa Embeddings No Contextuales:\n",
            "          Val Accuracy  Test Accuracy  Val F1 (weighted)  Test F1 (weighted)\n",
            "Word2Vec      0.541101       0.536812           0.539087            0.534706\n",
            "FastText      0.543781       0.543960           0.541850            0.541818\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec, FastText\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Preparar tokens\n",
        "df_train = pd.read_pickle(\"data/data_clean/train_tokenized.pkl\")\n",
        "sentences = df_train[\"tokens\"].tolist()\n",
        "y = df_train[\"bias\"].values\n",
        "\n",
        "# Train / Val / Test split (60/20/20)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    texts, y, test_size=0.15, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 2. Del 85% restante, tomamos el ~17.65% para que sea el 15% del total original\n",
        "# (0.15 / 0.85 = 0.17647...)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.1765, random_state=42, stratify=y_temp\n",
        ")\n",
        "results = {}\n",
        "\n",
        "# -------------------\n",
        "# Word2Vec\n",
        "# -------------------\n",
        "w2v_model = Word2Vec(sentences=X_train, vector_size=100, window=5, min_count=3, workers=1, sg=1)\n",
        "w2v_model.save(\"data/embeddings/word2vec.model\")\n",
        "\n",
        "# Promediar embeddings por frase\n",
        "def get_avg_w2v(sentence, model):\n",
        "    vecs = [model.wv[word] for word in sentence if word in model.wv]\n",
        "    if len(vecs) == 0:\n",
        "        return np.zeros(model.vector_size)\n",
        "    return np.mean(vecs, axis=0)\n",
        "\n",
        "X_train_vec = np.array([get_avg_w2v(s, w2v_model) for s in X_train])\n",
        "X_val_vec = np.array([get_avg_w2v(s, w2v_model) for s in X_val])\n",
        "X_test_vec = np.array([get_avg_w2v(s, w2v_model) for s in X_test])\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_vec, y_train)\n",
        "y_val_pred = clf.predict(X_val_vec)\n",
        "y_test_pred = clf.predict(X_test_vec)\n",
        "\n",
        "results[\"Word2Vec\"] = {\n",
        "    \"Val Accuracy\": accuracy_score(y_val, y_val_pred),\n",
        "    \"Test Accuracy\": accuracy_score(y_test, y_test_pred),\n",
        "    \"Val F1 (weighted)\": f1_score(y_val, y_val_pred, average=\"weighted\"),\n",
        "    \"Test F1 (weighted)\": f1_score(y_test, y_test_pred, average=\"weighted\")\n",
        "}\n",
        "\n",
        "print(\"Word2Vec - Classification Report (Test):\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# -------------------\n",
        "# FastText\n",
        "# -------------------\n",
        "fasttext_model = FastText(sentences=X_train, vector_size=100, window=5, min_count=3, workers=1, sg=1)\n",
        "fasttext_model.save(\"data/embeddings/fasttext.model\")\n",
        "\n",
        "X_train_vec = np.array([get_avg_w2v(s, fasttext_model) for s in X_train])\n",
        "X_val_vec = np.array([get_avg_w2v(s, fasttext_model) for s in X_val])\n",
        "X_test_vec = np.array([get_avg_w2v(s, fasttext_model) for s in X_test])\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_vec, y_train)\n",
        "y_val_pred = clf.predict(X_val_vec)\n",
        "y_test_pred = clf.predict(X_test_vec)\n",
        "\n",
        "results[\"FastText\"] = {\n",
        "    \"Val Accuracy\": accuracy_score(y_val, y_val_pred),\n",
        "    \"Test Accuracy\": accuracy_score(y_test, y_test_pred),\n",
        "    \"Val F1 (weighted)\": f1_score(y_val, y_val_pred, average=\"weighted\"),\n",
        "    \"Test F1 (weighted)\": f1_score(y_test, y_test_pred, average=\"weighted\")\n",
        "}\n",
        "\n",
        "print(\"FastText - Classification Report (Test):\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# -------------------\n",
        "# Resultados finales\n",
        "# -------------------\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"\\nComparativa Embeddings No Contextuales:\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3.3 Embeddings contextuales**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ace6881e7a9743a2a6daaed5eae95404",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/525 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence Transformers - Classification Report (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.54      0.53      1950\n",
            "           1       0.54      0.48      0.51      1598\n",
            "           2       0.55      0.57      0.56      2048\n",
            "\n",
            "    accuracy                           0.54      5596\n",
            "   macro avg       0.54      0.53      0.53      5596\n",
            "weighted avg       0.54      0.54      0.54      5596\n",
            "\n",
            "BERT - Classification Report (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.12      0.17      0.14         6\n",
            "           1       0.67      0.57      0.62         7\n",
            "           2       0.33      0.29      0.31         7\n",
            "\n",
            "    accuracy                           0.35        20\n",
            "   macro avg       0.38      0.34      0.36        20\n",
            "weighted avg       0.39      0.35      0.37        20\n",
            "\n",
            "\n",
            "Comparativa Embeddings Contextuales:\n",
            "                       Val Accuracy  Test Accuracy  Val F1 (weighted)  \\\n",
            "Sentence Transformers      0.526626        0.53574           0.525582   \n",
            "BERT                       0.350000        0.35000           0.343254   \n",
            "\n",
            "                       Test F1 (weighted)  \n",
            "Sentence Transformers            0.535128  \n",
            "BERT                             0.365934  \n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Preparar textos\n",
        "df_train = pd.read_pickle(\"data/data_clean/train_tokenized.pkl\")\n",
        "df_train[\"text_joined\"] = df_train[\"tokens\"].apply(lambda x: \" \".join(x))\n",
        "texts = df_train[\"text_joined\"].tolist()\n",
        "y = df_train[\"bias\"].values\n",
        "\n",
        "# Train / Val / Test split\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    texts, y, test_size=0.15, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 2. Del 85% restante, tomamos el ~17.65% para que sea el 15% del total original\n",
        "# (0.15 / 0.85 = 0.17647...)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.1765, random_state=42, stratify=y_temp\n",
        ")\n",
        "results = {}\n",
        "\n",
        "# -------------------\n",
        "# Sentence Transformers\n",
        "# -------------------\n",
        "st_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "X_train_vec = st_model.encode(X_train, batch_size=32, show_progress_bar=True)\n",
        "X_val_vec = st_model.encode(X_val, batch_size=32)\n",
        "X_test_vec = st_model.encode(X_test, batch_size=32)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_vec, y_train)\n",
        "y_val_pred = clf.predict(X_val_vec)\n",
        "y_test_pred = clf.predict(X_test_vec)\n",
        "\n",
        "results[\"Sentence Transformers\"] = {\n",
        "    \"Val Accuracy\": accuracy_score(y_val, y_val_pred),\n",
        "    \"Test Accuracy\": accuracy_score(y_test, y_test_pred),\n",
        "    \"Val F1 (weighted)\": f1_score(y_val, y_val_pred, average=\"weighted\"),\n",
        "    \"Test F1 (weighted)\": f1_score(y_test, y_test_pred, average=\"weighted\")\n",
        "}\n",
        "\n",
        "print(\"Sentence Transformers - Classification Report (Test):\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# -------------------\n",
        "# BERT (limitado a 100 textos para no saturar memoria)\n",
        "# -------------------\n",
        "bert_model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
        "bert_model = BertModel.from_pretrained(bert_model_name)\n",
        "bert_model.eval()\n",
        "\n",
        "def bert_sentence_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)\n",
        "        embeddings = outputs.last_hidden_state.squeeze(0)\n",
        "        return embeddings.mean(dim=0).numpy()\n",
        "\n",
        "X_train_subset = X_train[:100]\n",
        "X_val_subset = X_val[:20]\n",
        "X_test_subset = X_test[:20]\n",
        "y_train_subset = y_train[:100]\n",
        "y_val_subset = y_val[:20]\n",
        "y_test_subset = y_test[:20]\n",
        "\n",
        "X_train_vec = np.array([bert_sentence_embedding(t) for t in X_train_subset])\n",
        "X_val_vec = np.array([bert_sentence_embedding(t) for t in X_val_subset])\n",
        "X_test_vec = np.array([bert_sentence_embedding(t) for t in X_test_subset])\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_vec, y_train_subset)\n",
        "y_val_pred = clf.predict(X_val_vec)\n",
        "y_test_pred = clf.predict(X_test_vec)\n",
        "\n",
        "results[\"BERT\"] = {\n",
        "    \"Val Accuracy\": accuracy_score(y_val_subset, y_val_pred),\n",
        "    \"Test Accuracy\": accuracy_score(y_test_subset, y_test_pred),\n",
        "    \"Val F1 (weighted)\": f1_score(y_val_subset, y_val_pred, average=\"weighted\"),\n",
        "    \"Test F1 (weighted)\": f1_score(y_test_subset, y_test_pred, average=\"weighted\")\n",
        "}\n",
        "\n",
        "print(\"BERT - Classification Report (Test):\")\n",
        "print(classification_report(y_test_subset, y_test_pred))\n",
        "\n",
        "# -------------------\n",
        "# Resultados finales\n",
        "# -------------------\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"\\nComparativa Embeddings Contextuales:\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvy29jCJWbqI"
      },
      "source": [
        "# **4. Tabla Comparativa de Resultados**\n",
        "\n",
        "Para la fecha límite de esta entrega solo hemos podido hacer completamente la tarea de la variable bias. Las tareas de topic y source solo tienen presencia en la sección de Shallow Learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4.1 Shallow Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para entender los resultados, hay que aclarar los parámetros utilizados para cada variable en Shallow Learning.\n",
        "\n",
        "En el caso de la variable source, hemos tenido que reducir el número de estimadores del Random Forest de 300 a 150. Además, el número de estimadores del XGBoost también ha sido reducido de 200 a 75. Sin esta reducción, no habríamos sido capaces de terminar la ejecución de la celda. Ha llegado a estar más de una hora y seguía sin terminar de ejecutarse.\n",
        "\n",
        "En cuanto a la variable topic, además de las rebajas aplicadas al caso de la variable source, hemos decidido quitar el modelo XGBoost, ya que no termina de ejecutarse. Disponemos de equipos con capacidades técnicas muy limitadas, por lo que, con mejores ordenadores, no se tendrían que reducir los valores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Resultados de Clasificación Shallow Learning (TF-IDF)\n",
            "\n",
            "           Métricas     Bias             Topic            Source         \n",
            "              Model Accuracy Macro-F1 Accuracy Macro-F1 Accuracy Macro-F1\n",
            "Logistic Regression   0.7021   0.7001   0.5811   0.3390   0.5034   0.1031\n",
            "          LinearSVC   0.6987   0.6966   0.5892   0.4102   0.5591   0.2196\n",
            "      Random Forest   0.6937   0.6906   0.5204   0.2445   0.4996   0.4996\n"
          ]
        }
      ],
      "source": [
        "# Resultados de clasificación por variable objetivo\n",
        "\n",
        "results_bias = {\n",
        "    \"Logistic Regression\": {\"Accuracy\": 0.702109, \"Macro-F1\": 0.700091},\n",
        "    \"LinearSVC\": {\"Accuracy\": 0.698713, \"Macro-F1\": 0.696551},\n",
        "    \"Random Forest\": {\"Accuracy\": 0.693710, \"Macro-F1\": 0.690578}\n",
        "}\n",
        "\n",
        "results_topic = {\n",
        "    \"Logistic Regression\": {\"Accuracy\": 0.581129, \"Macro-F1\": 0.338987},\n",
        "    \"LinearSVC\": {\"Accuracy\": 0.589171, \"Macro-F1\": 0.410156},\n",
        "    \"Random Forest\": {\"Accuracy\": 0.520372, \"Macro-F1\": 0.244504}\n",
        "    }\n",
        "\n",
        "\n",
        "results_source = {\n",
        "    \"Logistic Regression\": {\"Accuracy\": 0.503401, \"Macro-F1\": 0.103117},\n",
        "    \"LinearSVC\": {\"Accuracy\": 0.559076, \"Macro-F1\": 0.219572},\n",
        "    \"Random Forest\": {\"Accuracy\": 0.499642, \"Macro-F1\": 0.499642}\n",
        "    }\n",
        "\n",
        "\n",
        "# --- Creación del DataFrame de Comparación ---\n",
        "rows = []\n",
        "models = [\"Logistic Regression\", \"LinearSVC\", \"Random Forest\"]\n",
        "\n",
        "for model in models:\n",
        "    row = {\n",
        "        \"Model\": model,\n",
        "        \"Bias Accuracy\": results_bias[model][\"Accuracy\"],\n",
        "        \"Bias Macro-F1\": results_bias[model][\"Macro-F1\"],\n",
        "        \"Topic Accuracy\": results_topic[model][\"Accuracy\"],\n",
        "        \"Topic Macro-F1\": results_topic[model][\"Macro-F1\"],\n",
        "        \"Source Accuracy\": results_source[model][\"Accuracy\"],\n",
        "        \"Source Macro-F1\": results_source[model][\"Macro-F1\"]\n",
        "    }\n",
        "    rows.append(row)\n",
        "\n",
        "df_comparison = pd.DataFrame(rows)\n",
        "\n",
        "# --- Formateo para la presentación ---\n",
        "\n",
        "# Redondear todas las columnas de métricas a 4 decimales\n",
        "df_display = df_comparison.round(4)\n",
        "\n",
        "# Crear un multi-índice para los nombres de las columnas para agrupar las métricas\n",
        "cols = [('Métricas', 'Model'), \n",
        "        ('Bias', 'Accuracy'), ('Bias', 'Macro-F1'),\n",
        "        ('Topic', 'Accuracy'), ('Topic', 'Macro-F1'),\n",
        "        ('Source', 'Accuracy'), ('Source', 'Macro-F1')]\n",
        "\n",
        "df_display.columns = pd.MultiIndex.from_tuples(cols)\n",
        "\n",
        "# Imprimir la tabla\n",
        "print(\" Resultados de Clasificación Shallow Learning (TF-IDF)\\n\")\n",
        "# Usar to_markdown o to_string para una salida limpia en consola\n",
        "print(df_display.to_string(index=False))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1- Bias:\n",
        "Todos los modelos presentan un desempeño sólido. Logistic Regression alcanza un accuracy de 0.7021 y un macro-F1 de 0.7001, seguido muy de cerca por LinearSVC, con un accuracy de 0.6987 y macro-F1 0.6966,  y Random Forest, con un accuracy de  0.6937 y  macro-F1 0.6906. Esto indica que las diferencias de sesgo en los textos son relativamente fáciles de capturar mediante TF-IDF, que identifica patrones de palabras relevantes para el sesgo.\n",
        "\n",
        "2- Topic:\n",
        "Los modelos lineales, especialmente LinearSVC, logran los mejores resultados, con un accuracy de  0.5892 y macro-F1 0.4102. Random Forest y Logistic Regression muestran un desempeño menor. Esto refuerza que, para la clasificación por tópicos, los modelos lineales son más adecuados con TF-IDF, que captura eficazmente términos distintivos de cada tema.\n",
        "\n",
        "3- Source:\n",
        "El desempeño general es más bajo. LinearSVC alcanza un accuracy de 0.5591 y un macro-F1 de 0.2196, mientras que Logistic Regression y Random Forest presentan métricas inferiores. Esto refleja la dificultad de diferenciar la fuente del texto únicamente con TF-IDF, ya que las diferencias estilísticas entre fuentes son más sutiles y menos evidentes en representaciones basadas en frecuencias de palabras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4.2 Deep Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rendimiento de Modelos de Deep Learning (LSTM & GRU)\n",
            "\n",
            "Estrategia de Embedding   Modelo  Accuracy  Macro-F1\n",
            "            Finetuneado     LSTM    0.4968    0.4947\n",
            "            Finetuneado      GRU    0.5273    0.5274\n",
            "         No Finetuneado     LSTM    0.4157    0.4064\n",
            "         No Finetuneado      GRU    0.3660    0.1786\n",
            "      Word2Vec (Frozen) Word2Vec    0.5454    0.5411\n",
            "   Word2Vec (Fine-tune) Word2Vec    0.4383    0.4179\n",
            "     Word2Vec (Scratch) Word2Vec    0.4039    0.3774\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data_finetune = {\n",
        "    \"Modelo\": [\"LSTM\", \"GRU\"],\n",
        "    \"Estrategia de Embedding\": [\"Finetuneado\", \"Finetuneado\"],\n",
        "    \"Accuracy\": [0.496783, 0.527281],\n",
        "    \"Macro-F1\": [0.494741, 0.527386]\n",
        "}\n",
        "\n",
        "data_random = {\n",
        "    \"Modelo\": [\"LSTM\", \"GRU\"],\n",
        "    \"Estrategia de Embedding\": [\"No Finetuneado\", \"No Finetuneado\"],\n",
        "    \"Accuracy\": [0.415654, 0.365976],\n",
        "    \"Macro-F1\": [0.406401, 0.178615]\n",
        "}\n",
        "\n",
        "data_word2vec = {\n",
        "    \"Modelo\": [\"Word2Vec\", \"Word2Vec\", \"Word2Vec\"],\n",
        "    \"Estrategia de Embedding\": [\n",
        "        \"Word2Vec (Frozen)\",\n",
        "        \"Word2Vec (Fine-tune)\",\n",
        "        \"Word2Vec (Scratch)\"\n",
        "    ],\n",
        "    \"Accuracy\": [0.545390, 0.438349, 0.403860],\n",
        "    \"Macro-F1\": [0.541059, 0.417913, 0.377377]\n",
        "}\n",
        "\n",
        "# Crear DataFrames\n",
        "df_finetune = pd.DataFrame(data_finetune)\n",
        "df_random = pd.DataFrame(data_random)\n",
        "df_word2vec = pd.DataFrame(data_word2vec)\n",
        "\n",
        "# Unir todos los DataFrames\n",
        "df_deep_learning = pd.concat(\n",
        "    [df_finetune, df_random, df_word2vec],\n",
        "    ignore_index=True\n",
        ")\n",
        "\n",
        "# Redondear métricas para presentación\n",
        "df_deep_learning_display = df_deep_learning.round(4)\n",
        "\n",
        "# Reordenar columnas\n",
        "column_order = [\"Estrategia de Embedding\", \"Modelo\", \"Accuracy\", \"Macro-F1\"]\n",
        "df_deep_learning_display = df_deep_learning_display[column_order]\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Rendimiento de Modelos de Deep Learning (LSTM & GRU)\\n\")\n",
        "print(df_deep_learning_display.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Embeddings finetuneados:\n",
        "\n",
        "Cuando los embeddings aprenden conjuntamente con el modelo, GRU supera ligeramente a LSTM, alcanzando un accuracy de 0.5273 y un macro-F1 de 0.5274. LSTM obtiene valores algo inferiores con un accuracy de 0.4968. Esta diferencia puede explicarse por la estructura más simple de GRU, que suele generalizar mejor en escenarios con datasets de tamaño moderado.\n",
        "\n",
        "Embeddings no finetuneado: \n",
        "\n",
        "Ambos modelos sufren una caída notable de rendimiento, especialmente GRU, cuyo macro-F1 desciende hasta 0.1786. Esto indica una incapacidad del modelo para aprender representaciones semánticas útiles a partir de embeddings no informativos.\n",
        "\n",
        "Word2Vec:\n",
        "\n",
        "El mejor rendimiento global se obtiene con Word2Vec congelado, alcanzando un accuracy de 0.5454 y un macro-F1 de 0.5411. Esto sugiere que los embeddings preentrenados capturan información semántica relevante, que el modelo puede explotar eficazmente sin necesidad de reajustarlos.\n",
        "\n",
        "\n",
        "\n",
        "En conjunto, los resultados confirman que la estrategia de embedding es el factor clave en el rendimiento. Ademas, los embeddings preentrenados y congelados Word2Vec Frozen superan a las alternativas entrenadas desde cero. Por ultimo, GRU tiende a comportarse ligeramente mejor que LSTM cuando los embeddings se aprenden.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4.3 Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultados Consolidados de Modelos de Representación de Texto (Test Set)\n",
            "\n",
            "Tipo de Embedding        Modelo/Técnica  Accuracy  Macro-F1\n",
            "      Tradicional                TF-IDF    0.7100    0.7001\n",
            "      Tradicional    Bag-of-Words (BoW)    0.6300    0.6337\n",
            "    No Contextual              Word2Vec    0.5368    0.5347\n",
            "    No Contextual              FastText    0.5440    0.5418\n",
            "       Contextual Sentence Transformers    0.5351    0.5351\n",
            "       Contextual                  BERT    0.3659    0.3659\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- Datos nuevos ---\n",
        "\n",
        "# Tradicionales (Shallow Learning)\n",
        "results_traditional = {\n",
        "    \"Modelo/Técnica\": [\"TF-IDF\", \"Bag-of-Words (BoW)\"],\n",
        "    \"Test Accuracy\": [0.7100, 0.6300],\n",
        "    \"Test F1 (weighted)\": [0.7001, 0.6337]  # macro-F1 ponderado\n",
        "}\n",
        "\n",
        "# No contextuales (Word2Vec / FastText)\n",
        "results_non_contextual = {\n",
        "    \"Modelo/Técnica\": [\"Word2Vec\", \"FastText\"],\n",
        "    \"Test Accuracy\": [0.5368, 0.5440],\n",
        "    \"Test F1 (weighted)\": [0.5347, 0.5418]\n",
        "}\n",
        "\n",
        "# Contextuales (Sentence Transformers / BERT)\n",
        "results_contextual = {\n",
        "    \"Modelo/Técnica\": [\"Sentence Transformers\", \"BERT\"],\n",
        "    \"Test Accuracy\": [0.5351, 0.3659],\n",
        "    \"Test F1 (weighted)\": [0.5351, 0.3659]\n",
        "}\n",
        "\n",
        "# --- Crear DataFrames ---\n",
        "df_traditional = pd.DataFrame(results_traditional).assign(Tipo_Embedding=\"Tradicional\")\n",
        "df_non_contextual = pd.DataFrame(results_non_contextual).assign(Tipo_Embedding=\"No Contextual\")\n",
        "df_contextual = pd.DataFrame(results_contextual).assign(Tipo_Embedding=\"Contextual\")\n",
        "\n",
        "# --- Concatenar todos los DataFrames ---\n",
        "df_results = pd.concat([df_traditional, df_non_contextual, df_contextual], ignore_index=True)\n",
        "\n",
        "# --- Ordenar columnas y renombrar ---\n",
        "df_results = df_results[[\"Tipo_Embedding\", \"Modelo/Técnica\", \"Test Accuracy\", \"Test F1 (weighted)\"]]\n",
        "df_results.rename(columns={\"Tipo_Embedding\": \"Tipo de Embedding\",\n",
        "                           \"Test Accuracy\": \"Accuracy\",\n",
        "                           \"Test F1 (weighted)\": \"Macro-F1\"}, inplace=True)\n",
        "\n",
        "# Redondear métricas\n",
        "df_results[[\"Accuracy\", \"Macro-F1\"]] = df_results[[\"Accuracy\", \"Macro-F1\"]].round(4)\n",
        "\n",
        "# --- Mostrar tabla ---\n",
        "print(\"Resultados Consolidados de Modelos de Representación de Texto (Test Set)\\n\")\n",
        "print(df_results.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Embeddings tradicionales: \n",
        "\n",
        "Son los que obtienen el mejor rendimiento en Accuracy y Macro-F1, especialmente TF-IDF,  con0.71 y 0.70 respectivamente.Esto indica que para esta tarea, las representaciones basadas en frecuencia de términos todavía capturan bien los patrones discriminativos del texto, particularmente para la variable objetivo \"Bias\".\n",
        "\n",
        "Por otro lado, Bag-of-Words rinde un poco peor que TF-IDF, lo que es esperado ya que TF-IDF pondera la importancia de los términos, ayudando a resaltar palabras clave.\n",
        "\n",
        "Embeddings no contextuales: \n",
        "\n",
        "Este tipo de embeddings obtienen resultados moderados, con 0.54–0.544 de Accuracy y  0.53–0.54 de Macro-F1. Aunque capturan relaciones semánticas entre palabras, al usarlos con Logistic Regression sobre un downstream classification, no superan a TF-IDF.\n",
        "\n",
        "Esto sugiere que la información semántica que Word2Vec o FastText aportan no es tan crítica para la tarea como la presencia o frecuencia de términos concretos.\n",
        "\n",
        "Embeddings contextuales:\n",
        "\n",
        "Sentence Transformers se comporta similar a los embeddings no contextuales (~0.535).\n",
        "\n",
        "BERT rinde mucho peor (0.366 de Accuracy, 0.366 de Macro-F1), probablemente por:\n",
        "\n",
        "El tamaño reducido del set de entrenamiento para BERT.\n",
        "\n",
        "Su complejidad hace que necesite fine-tuning para obtener buen desempeño, y aquí se usó un embedding fijo.\n",
        "\n",
        "Esto indica que sin fine-tuning, BERT no es útil para esta tarea con un clasificador lineal como Logistic Regression.\n",
        "\n",
        "Conclusión general\n",
        "\n",
        "Para esta tarea de clasificación de sesgo con Logistic Regression:\n",
        "\n",
        "TF-IDF sigue siendo la representación más efectiva.\n",
        "\n",
        "Los embeddings Word2Vec/FastText y Sentence Transformers son útiles pero no superan a las técnicas basadas en frecuencia de términos.\n",
        "\n",
        "BERT requiere ajustes adicionales (fine-tuning) para ser competitivo."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
