{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqfT1kYc_EOn"
      },
      "source": [
        "# **1. Shallow Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from gensim.models import Word2Vec\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, GRU, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from gensim.models import Word2Vec\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clases en bias: bias\n",
            "2    10240\n",
            "0     9750\n",
            "1     7988\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Entrenando modelos... (mucho más rápido ahora)\n",
            "\n",
            "Entrenando Logistic Regression...\n",
            "Entrenando LinearSVC...\n",
            "Entrenando Random Forest...\n",
            "Entrenando XGBoost...\n",
            "\n",
            "Resultados comparativos Shallow Learning:\n",
            "\n",
            "                     Accuracy  Macro-F1\n",
            "Logistic Regression  0.696926  0.694518\n",
            "LinearSVC            0.693531  0.690891\n",
            "Random Forest        0.694425  0.690053\n",
            "XGBoost              0.743924  0.743006\n"
          ]
        }
      ],
      "source": [
        "# Cargamos dataset tokenizado\n",
        "df_train = pd.read_pickle(\"data/data_clean/train_tokenized.pkl\")\n",
        "\n",
        "print(\"Clases en bias:\", df_train[\"bias\"].value_counts())\n",
        "\n",
        "os.makedirs(\"data/models\", exist_ok=True)\n",
        "\n",
        "# Usamos la columna correcta\n",
        "df_train[\"text_joined\"] = df_train[\"tokens\"].apply(lambda x: \" \".join(x))\n",
        "\n",
        "# TF-IDF optimizado\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=3000,\n",
        "    stop_words=\"english\",\n",
        "    ngram_range=(1, 2)\n",
        ")\n",
        "\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df_train[\"text_joined\"])\n",
        "y = df_train[\"bias\"].values\n",
        "\n",
        "# Train/val\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "    X_tfidf, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# Entrenar modelos\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, n_jobs=-1),\n",
        "    \"LinearSVC\": LinearSVC(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=150, n_jobs=-1),\n",
        "    \"XGBoost\": XGBClassifier(\n",
        "        n_estimators=200,\n",
        "        eval_metric=\"mlogloss\",\n",
        "        tree_method=\"hist\",\n",
        "        n_jobs=-1\n",
        "    )\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "print(\"\\nEntrenando modelos... (mucho más rápido ahora)\\n\")\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Entrenando {name}...\")\n",
        "    model.fit(X_tr, y_tr)\n",
        "    y_pred = model.predict(X_val)\n",
        "    results[name] = {\n",
        "        \"Accuracy\": accuracy_score(y_val, y_pred),\n",
        "        \"Macro-F1\": f1_score(y_val, y_pred, average=\"macro\")\n",
        "    }\n",
        "    pickle.dump(model, open(f\"data/models/{name.replace(' ', '_').lower()}.pkl\", \"wb\"))\n",
        "\n",
        "# Guardamos TF-IDF\n",
        "pickle.dump(tfidf_vectorizer, open(\"data/features/tfidf_vectorizer.pkl\", \"wb\"))\n",
        "\n",
        "# Resultados\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"\\nResultados comparativos Shallow Learning:\\n\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para evaluar los modelos hemos usado Accuracy y Macro-F1, métricas adecuadas para problemas de clasificación con clases desbalanceadas.\n",
        "Los cuatro modelos presentan resultados parecidos. Sin embargo, XGBoost ofrece el mejor rendimiento, mostrando que puede capturar patrones complejos del sesgo ideológico mejor que modelos lineales o Random Forest.\n",
        "Por otro lado, los modelos lineales funcionan razonablemente bien, lo que indica que el sesgo tiene señales lineales claras en los términos más frecuentes.\n",
        "Elegimos estos cuatro modelos (Logistic Regression, LinearSVC, Random Forest y XGBoost) para cubrir tanto enfoques lineales como basados en árboles, y utilizar el dataset tokenizado con TF-IDF para representar el texto en forma dispersa, adecuada para Shallow Learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztbnwVJVWSgX"
      },
      "source": [
        "# **3. Modelos Deep**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En esta parte nos vamos a enfocar en la clasificación del sesgo. Los motivos son los siguientes:\n",
        "\n",
        "1- Detectar la orientación política de una noticia es la tarea principal del proyecto. Además, esta tarea permite evaluar cómo los modelos y embeddings capturan matices semánticos y patrones discursivos.\n",
        "2- Una vez concluida la clasificación de sesgo, se puede reutilizar la pipeline para las demás tareas de clasificación (medio y temática).\n",
        "3- La columna bias presenta un número moderadamente equilibrado de ejemplos por clase, lo que permite ajustar la arquitectura y los hiperparámetros de manera controlada antes de afrontar tareas más complejas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las razones de haber elegido las combinaciones de embeddings y arquitecturas de redes neuronales para abordar la clasificación del sesgo ideológicoson las siguientes:\n",
        "\n",
        "1- Comparación de embeddings no contextuales y contextuales:\n",
        "    -Los embeddings no contextuales como, Word2Vecy y FastText, permiten capturar relaciones semánticas entre palabras de manera estática.\n",
        "    -Los embeddings contextuales como, Sentence Transformers y BERT, capturan el significado de las palabras según su contexto en la frase, lo que es clave para detectar matices ideológicos más complejos.\n",
        "\n",
        "2- Exploración de diferentes estrategias de embeddings:\n",
        "    -Word2Vec congelado: usar embeddings preentrenados sin actualizar durante el entrenamiento, para evaluar la capacidad de vectores fijos.\n",
        "    -Word2Vec fine-tune: ajustar los vectores durante el entrenamiento para adaptarlos al corpus específico.\n",
        "    -Word2Vec “from scratch”: entrenar desde cero sobre el dataset, para capturar patrones propios del corpus.\n",
        "    -Para los embeddings contextuales, se compara Sentence Transformers preentrenado frente a BERT, con fine-tuning parcial o total según la arquitectura de la red.\n",
        "\n",
        "3- Elección de arquitecturas de redes neuronales:\n",
        "    -Redes totalmente conectadas (Dense): adecuadas para embeddings agregados o promedio de vectores de palabras.\n",
        "    -Redes recurrentes (LSTM/GRU): capturan secuencias y dependencias entre palabras, esenciales para comprender el flujo discursivo en los artículos.\n",
        "    -CNN para texto: permiten identificar patrones locales de n-gramas que son relevantes en la clasificación de sesgo.\n",
        "\n",
        "4- Razonamiento general:\n",
        "    -Combinar diferentes tipos de embeddings y arquitecturas permite evaluar cuál representa mejor la información semántica y estilística para cada tarea.\n",
        "    -Esta estrategia también permite analizar cómo el fine-tuning de embeddings impacta en la capacidad del modelo de captar señales ideológicas, frente a vectores preentrenados fijos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 322ms/step - accuracy: 0.4257 - loss: 1.0562 - val_accuracy: 0.4750 - val_loss: 1.0236\n",
            "Epoch 2/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 311ms/step - accuracy: 0.5227 - loss: 0.9537 - val_accuracy: 0.4959 - val_loss: 0.9828\n",
            "Epoch 3/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 340ms/step - accuracy: 0.5904 - loss: 0.8587 - val_accuracy: 0.5234 - val_loss: 0.9534\n",
            "Epoch 4/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 428ms/step - accuracy: 0.6674 - loss: 0.7404 - val_accuracy: 0.5173 - val_loss: 1.0088\n",
            "Epoch 5/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 373ms/step - accuracy: 0.7374 - loss: 0.6141 - val_accuracy: 0.5116 - val_loss: 1.0896\n",
            "Epoch 6/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 521ms/step - accuracy: 0.8024 - loss: 0.4791 - val_accuracy: 0.5046 - val_loss: 1.2833\n",
            "Epoch 7/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 1s/step - accuracy: 0.8611 - loss: 0.3566 - val_accuracy: 0.5095 - val_loss: 1.3578\n",
            "Epoch 8/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 1s/step - accuracy: 0.8989 - loss: 0.2583 - val_accuracy: 0.5114 - val_loss: 1.6459\n",
            "Epoch 9/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 533ms/step - accuracy: 0.9331 - loss: 0.1715 - val_accuracy: 0.5161 - val_loss: 1.8227\n",
            "Epoch 10/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 380ms/step - accuracy: 0.9541 - loss: 0.1253 - val_accuracy: 0.5134 - val_loss: 2.1535\n",
            "Epoch 1/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 290ms/step - accuracy: 0.4016 - loss: 1.0760 - val_accuracy: 0.4307 - val_loss: 1.0498\n",
            "Epoch 2/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 367ms/step - accuracy: 0.4854 - loss: 1.0039 - val_accuracy: 0.4805 - val_loss: 0.9938\n",
            "Epoch 3/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 331ms/step - accuracy: 0.5812 - loss: 0.8742 - val_accuracy: 0.5088 - val_loss: 0.9586\n",
            "Epoch 4/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 320ms/step - accuracy: 0.6687 - loss: 0.7393 - val_accuracy: 0.5079 - val_loss: 0.9995\n",
            "Epoch 5/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 318ms/step - accuracy: 0.7584 - loss: 0.5768 - val_accuracy: 0.5250 - val_loss: 1.0911\n",
            "Epoch 6/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 323ms/step - accuracy: 0.8357 - loss: 0.4116 - val_accuracy: 0.5366 - val_loss: 1.2710\n",
            "Epoch 7/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 474ms/step - accuracy: 0.8903 - loss: 0.2854 - val_accuracy: 0.5359 - val_loss: 1.4438\n",
            "Epoch 8/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 618ms/step - accuracy: 0.9309 - loss: 0.1858 - val_accuracy: 0.5229 - val_loss: 1.7583\n",
            "Epoch 9/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 414ms/step - accuracy: 0.9538 - loss: 0.1276 - val_accuracy: 0.5304 - val_loss: 1.9515\n",
            "Epoch 10/10\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 350ms/step - accuracy: 0.9701 - loss: 0.0880 - val_accuracy: 0.5264 - val_loss: 2.2296\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 85ms/step\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 71ms/step\n",
            "Resultados:\n",
            "      Accuracy  Macro-F1\n",
            "LSTM  0.513402  0.514574\n",
            "GRU   0.526447  0.526548\n"
          ]
        }
      ],
      "source": [
        "# Cargamos el dataset tokenizado\n",
        "df_train = pd.read_pickle(\"data/data_clean/train_tokenized.pkl\")\n",
        "y = df_train[\"bias\"].values\n",
        "\n",
        "# Codificamos los labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "y_cat = to_categorical(y_encoded)\n",
        "\n",
        "# Split train/validation\n",
        "X_tr_text, X_val_text, y_tr, y_val = train_test_split(\n",
        "    df_train[\"tokens\"], y_cat, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Cargamos el Word2Vec preentrenado de la anterior entrega\n",
        "w2v_model = Word2Vec.load(\"data/embeddings/word2vec.model\")\n",
        "embedding_dim = w2v_model.vector_size\n",
        "\n",
        "# Creamos el vocabulario e índices\n",
        "word_index = {word: i+1 for i, word in enumerate(w2v_model.wv.index_to_key)}\n",
        "vocab_size = len(word_index) + 1  # +1 para padding\n",
        "\n",
        "# Convertimos los tokens a índices\n",
        "def tokens_to_indices(tokens, word_index):\n",
        "    return [word_index[t] for t in tokens if t in word_index]\n",
        "\n",
        "X_tr_idx = [tokens_to_indices(t, word_index) for t in X_tr_text]\n",
        "X_val_idx = [tokens_to_indices(t, word_index) for t in X_val_text]\n",
        "\n",
        "# Aplciamos padding\n",
        "max_seq_len = 200\n",
        "X_tr_pad = pad_sequences(X_tr_idx, maxlen=max_seq_len, padding='post')\n",
        "X_val_pad = pad_sequences(X_val_idx, maxlen=max_seq_len, padding='post')\n",
        "\n",
        "# Creamos la matriz de embedding \n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_matrix[i] = w2v_model.wv[word]\n",
        "\n",
        "# Definimos y entrenaos los modelos \n",
        "\n",
        "def build_rnn(model_type='LSTM'):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=vocab_size,\n",
        "                        output_dim=embedding_dim,\n",
        "                        weights=[embedding_matrix],\n",
        "                        input_length=max_seq_len,\n",
        "                        trainable=True))  # Fine-tune embeddings\n",
        "    if model_type == 'LSTM':\n",
        "        model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "    elif model_type == 'GRU':\n",
        "        model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-3),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# LSTM\n",
        "lstm_model = build_rnn('LSTM')\n",
        "lstm_history = lstm_model.fit(X_tr_pad, y_tr,\n",
        "                              validation_data=(X_val_pad, y_val),\n",
        "                              epochs=10,\n",
        "                              batch_size=64)\n",
        "\n",
        "# GRU\n",
        "gru_model = build_rnn('GRU')\n",
        "gru_history = gru_model.fit(X_tr_pad, y_tr,\n",
        "                            validation_data=(X_val_pad, y_val),\n",
        "                            epochs=10,\n",
        "                            batch_size=64)\n",
        "\n",
        "# Evaluamos los modelos\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Predicciones\n",
        "y_pred_lstm = lstm_model.predict(X_val_pad, batch_size=64)\n",
        "y_pred_gru = gru_model.predict(X_val_pad, batch_size=64)\n",
        "\n",
        "y_pred_lstm_labels = np.argmax(y_pred_lstm, axis=1)\n",
        "y_pred_gru_labels = np.argmax(y_pred_gru, axis=1)\n",
        "y_val_labels = np.argmax(y_val, axis=1)\n",
        "\n",
        "# Métricas\n",
        "results = {\n",
        "    'LSTM': {\n",
        "        'Accuracy': accuracy_score(y_val_labels, y_pred_lstm_labels),\n",
        "        'Macro-F1': f1_score(y_val_labels, y_pred_lstm_labels, average='macro')\n",
        "    },\n",
        "    'GRU': {\n",
        "        'Accuracy': accuracy_score(y_val_labels, y_pred_gru_labels),\n",
        "        'Macro-F1': f1_score(y_val_labels, y_pred_gru_labels, average='macro')\n",
        "    }\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"Resultados:\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-Rendimiento general:\n",
        "   -Ambos modelos muestran resultados muy similares, con valores en torno al 53–54%, tanto en Accuracy como en Macro-F1. Esto indica que:\n",
        "       -Los dos modelos capturan de forma parecida los patrones secuenciales del sesgo ideológico.\n",
        "       -No existe una ventaja clara de ninguno de los dos modelos neuronales en este dataset.\n",
        "-Interpretación:\n",
        "    -El rendimiento indica que el sesgo ideológico es una tarea difícil incluso para modelos neuronales. \n",
        "    -Puede que los textos no tengan suficiente señal secuencial para que LSTM/GRU destaquen claramente.\n",
        "-Conclusión:\n",
        "    -Ambos modelos presentan un rendimiento equivalente, pero al ser  ligeramente superior, hemos decidido usar LSTM  como baseline de deep learning. Sin embargo, estas arquitecturas probablemente no capturan matices ideológicos complejos, por lo que se es necesario explorar  modelos más potentes como BERT o RoBERTa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'text_joined'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyError\u001b[39m: 'text_joined'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cargar dataset tokenizado\u001b[39;00m\n\u001b[32m      2\u001b[39m df = pd.read_pickle(\u001b[33m\"\u001b[39m\u001b[33mdata/data_clean/train_tokenized.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m texts = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext_joined\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.astype(\u001b[38;5;28mstr\u001b[39m).tolist()\n\u001b[32m      6\u001b[39m labels = df[\u001b[33m\"\u001b[39m\u001b[33mbias\u001b[39m\u001b[33m\"\u001b[39m].tolist()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Tokenizer\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\anaconda3\\envs\\nlp\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
            "\u001b[31mKeyError\u001b[39m: 'text_joined'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# -----------------------------\n",
        "#  Cargar dataset tokenizado\n",
        "# -----------------------------\n",
        "df = pd.read_pickle(\"data/data_clean/train_tokenized.pkl\")\n",
        "\n",
        "# Crear columna text_joined a partir de tokens\n",
        "df[\"text_joined\"] = df[\"tokens\"].apply(lambda x: \" \".join(x))\n",
        "\n",
        "texts = df[\"text_joined\"].astype(str).tolist()\n",
        "labels = df[\"bias\"].tolist()\n",
        "\n",
        "# -----------------------------\n",
        "#  Tokenización y secuencias\n",
        "# -----------------------------\n",
        "vocab_size = 20000\n",
        "maxlen = 100\n",
        "embedding_dim = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "X_seq = tokenizer.texts_to_sequences(texts)\n",
        "X = pad_sequences(X_seq, maxlen=maxlen)\n",
        "\n",
        "# Codificación de etiquetas\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(labels)\n",
        "\n",
        "# Train/validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "#  Modelos LSTM y GRU\n",
        "# -----------------------------\n",
        "def build_lstm_model():\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim, input_length=maxlen, trainable=False),\n",
        "        LSTM(128, return_sequences=False),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(len(np.unique(y)), activation='softmax')\n",
        "    ])\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        optimizer=\"adam\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def build_gru_model():\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim, input_length=maxlen, trainable=False),\n",
        "        GRU(128, return_sequences=False),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(len(np.unique(y)), activation='softmax')\n",
        "    ])\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        optimizer=\"adam\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# -----------------------------\n",
        "#  Entrenamiento LSTM\n",
        "# -----------------------------\n",
        "lstm_model = build_lstm_model()\n",
        "history_lstm = lstm_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=5,\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "#  Entrenamiento GRU\n",
        "# -----------------------------\n",
        "gru_model = build_gru_model()\n",
        "history_gru = gru_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=5,\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "#  Evaluación\n",
        "# -----------------------------\n",
        "def evaluate(model):\n",
        "    preds = np.argmax(model.predict(X_val), axis=1)\n",
        "    return accuracy_score(y_val, preds), f1_score(y_val, preds, average=\"macro\")\n",
        "\n",
        "acc_lstm, f1_lstm = evaluate(lstm_model)\n",
        "acc_gru, f1_gru = evaluate(gru_model)\n",
        "\n",
        "print(\"\\nResultados Embedding Random (NO fine-tuneado)\")\n",
        "print(\"LSTM → Accuracy:\", acc_lstm, \"Macro-F1:\", f1_lstm)\n",
        "print(\"GRU  → Accuracy:\", acc_gru, \"Macro-F1:\", f1_gru)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvy29jCJWbqI"
      },
      "source": [
        "# **5. Tabla Comaprativa de Resultados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7iaL0qQWhoh"
      },
      "source": [
        "# **6. Interpretabilidad**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
