{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e74c7bd",
   "metadata": {},
   "source": [
    "# **1. Deep Learning**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f2147c",
   "metadata": {},
   "source": [
    "<!-- ## **1. Imports** -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb3d9275",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch' has no attribute 'autograd' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, f1_score\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aaron\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\__init__.py:2059\u001b[39m\n\u001b[32m   2043\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2044\u001b[39m \u001b[38;5;66;03m# Import most common subpackages\u001b[39;00m\n\u001b[32m   2045\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2050\u001b[39m \n\u001b[32m   2051\u001b[39m \u001b[38;5;66;03m# needs to be before import torch.nn as nn to avoid circular dependencies\u001b[39;00m\n\u001b[32m   2052\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograd\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2053\u001b[39m     enable_grad \u001b[38;5;28;01mas\u001b[39;00m enable_grad,\n\u001b[32m   2054\u001b[39m     inference_mode \u001b[38;5;28;01mas\u001b[39;00m inference_mode,\n\u001b[32m   2055\u001b[39m     no_grad \u001b[38;5;28;01mas\u001b[39;00m no_grad,\n\u001b[32m   2056\u001b[39m     set_grad_enabled \u001b[38;5;28;01mas\u001b[39;00m set_grad_enabled,\n\u001b[32m   2057\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2059\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m   2060\u001b[39m     __config__ \u001b[38;5;28;01mas\u001b[39;00m __config__,\n\u001b[32m   2061\u001b[39m     __future__ \u001b[38;5;28;01mas\u001b[39;00m __future__,\n\u001b[32m   2062\u001b[39m     _awaits \u001b[38;5;28;01mas\u001b[39;00m _awaits,\n\u001b[32m   2063\u001b[39m     autograd \u001b[38;5;28;01mas\u001b[39;00m autograd,\n\u001b[32m   2064\u001b[39m     backends \u001b[38;5;28;01mas\u001b[39;00m backends,\n\u001b[32m   2065\u001b[39m     cpu \u001b[38;5;28;01mas\u001b[39;00m cpu,\n\u001b[32m   2066\u001b[39m     cuda \u001b[38;5;28;01mas\u001b[39;00m cuda,\n\u001b[32m   2067\u001b[39m     distributed \u001b[38;5;28;01mas\u001b[39;00m distributed,\n\u001b[32m   2068\u001b[39m     distributions \u001b[38;5;28;01mas\u001b[39;00m distributions,\n\u001b[32m   2069\u001b[39m     fft \u001b[38;5;28;01mas\u001b[39;00m fft,\n\u001b[32m   2070\u001b[39m     futures \u001b[38;5;28;01mas\u001b[39;00m futures,\n\u001b[32m   2071\u001b[39m     hub \u001b[38;5;28;01mas\u001b[39;00m hub,\n\u001b[32m   2072\u001b[39m     jit \u001b[38;5;28;01mas\u001b[39;00m jit,\n\u001b[32m   2073\u001b[39m     linalg \u001b[38;5;28;01mas\u001b[39;00m linalg,\n\u001b[32m   2074\u001b[39m     mps \u001b[38;5;28;01mas\u001b[39;00m mps,\n\u001b[32m   2075\u001b[39m     mtia \u001b[38;5;28;01mas\u001b[39;00m mtia,\n\u001b[32m   2076\u001b[39m     multiprocessing \u001b[38;5;28;01mas\u001b[39;00m multiprocessing,\n\u001b[32m   2077\u001b[39m     nested \u001b[38;5;28;01mas\u001b[39;00m nested,\n\u001b[32m   2078\u001b[39m     nn \u001b[38;5;28;01mas\u001b[39;00m nn,\n\u001b[32m   2079\u001b[39m     optim \u001b[38;5;28;01mas\u001b[39;00m optim,\n\u001b[32m   2080\u001b[39m     overrides \u001b[38;5;28;01mas\u001b[39;00m overrides,\n\u001b[32m   2081\u001b[39m     profiler \u001b[38;5;28;01mas\u001b[39;00m profiler,\n\u001b[32m   2082\u001b[39m     sparse \u001b[38;5;28;01mas\u001b[39;00m sparse,\n\u001b[32m   2083\u001b[39m     special \u001b[38;5;28;01mas\u001b[39;00m special,\n\u001b[32m   2084\u001b[39m     testing \u001b[38;5;28;01mas\u001b[39;00m testing,\n\u001b[32m   2085\u001b[39m     types \u001b[38;5;28;01mas\u001b[39;00m types,\n\u001b[32m   2086\u001b[39m     utils \u001b[38;5;28;01mas\u001b[39;00m utils,\n\u001b[32m   2087\u001b[39m     xpu \u001b[38;5;28;01mas\u001b[39;00m xpu,\n\u001b[32m   2088\u001b[39m )\n\u001b[32m   2089\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msignal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m windows \u001b[38;5;28;01mas\u001b[39;00m windows\n\u001b[32m   2092\u001b[39m \u001b[38;5;66;03m# Quantized, sparse, AO, etc. should be last to get imported, as nothing\u001b[39;00m\n\u001b[32m   2093\u001b[39m \u001b[38;5;66;03m# is expected to depend on them.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aaron\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\distributions\\__init__.py:116\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01muniform\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Uniform\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvon_mises\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VonMises\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mweibull\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Weibull\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwishart\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Wishart\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aaron\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\distributions\\von_mises.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmath\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjit\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constraints\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributions\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribution\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Distribution\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aaron\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\jit\\__init__.py:23\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# These are imported so users can access them from the `torch.jit` module\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_jit_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     _Await,\n\u001b[32m     11\u001b[39m     _drop,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     unused,\n\u001b[32m     22\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_async\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fork, wait\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_await\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _awaitable, _awaitable_nowait, _awaitable_wait\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_decomposition_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _register_decomposition\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aaron\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\jit\\_async.py:14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_jit_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Future\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_builtins\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _register_builtin\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m set_module\n\u001b[32m     18\u001b[39m set_module(Future, \u001b[33m\"\u001b[39m\u001b[33mtorch.jit\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aaron\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\jit\\_builtins.py:94\u001b[39m\n\u001b[32m     19\u001b[39m _builtin_table: Optional[Dict[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     21\u001b[39m _modules_containing_builtins = (torch, torch._C._nn, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._sparse, torch._C._special)  \u001b[38;5;66;03m# type: ignore[attr-defined] # noqa: B950\u001b[39;00m\n\u001b[32m     23\u001b[39m _builtin_ops = [\n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m# Pairs of (function, op_name)\u001b[39;00m\n\u001b[32m     25\u001b[39m     (_pair, \u001b[33m\"\u001b[39m\u001b[33maten::_pair\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     26\u001b[39m     (_quadruple, \u001b[33m\"\u001b[39m\u001b[33maten::_quadruple\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     27\u001b[39m     (_single, \u001b[33m\"\u001b[39m\u001b[33maten::_single\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     28\u001b[39m     (_triple, \u001b[33m\"\u001b[39m\u001b[33maten::_triple\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     29\u001b[39m     (_list_with_default, \u001b[33m\"\u001b[39m\u001b[33maten::list_with_default\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     30\u001b[39m     (OrderedDict, \u001b[33m\"\u001b[39m\u001b[33maten::dict\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     31\u001b[39m     (\u001b[38;5;28mdict\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33maten::dict\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     32\u001b[39m     (cudnn.is_acceptable, \u001b[33m\"\u001b[39m\u001b[33maten::cudnn_is_acceptable\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     33\u001b[39m     (math.ceil, \u001b[33m\"\u001b[39m\u001b[33maten::ceil\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     34\u001b[39m     (math.copysign, \u001b[33m\"\u001b[39m\u001b[33maten::copysign\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     35\u001b[39m     (math.erf, \u001b[33m\"\u001b[39m\u001b[33maten::erf\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     36\u001b[39m     (math.erfc, \u001b[33m\"\u001b[39m\u001b[33maten::erfc\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     37\u001b[39m     (math.exp, \u001b[33m\"\u001b[39m\u001b[33maten::exp\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     38\u001b[39m     (math.expm1, \u001b[33m\"\u001b[39m\u001b[33maten::expm1\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     39\u001b[39m     (math.fabs, \u001b[33m\"\u001b[39m\u001b[33maten::fabs\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     40\u001b[39m     (math.floor, \u001b[33m\"\u001b[39m\u001b[33maten::floor\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     41\u001b[39m     (math.gamma, \u001b[33m\"\u001b[39m\u001b[33maten::gamma\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     42\u001b[39m     (math.lgamma, \u001b[33m\"\u001b[39m\u001b[33maten::lgamma\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     43\u001b[39m     (math.log, \u001b[33m\"\u001b[39m\u001b[33maten::log\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     44\u001b[39m     (math.log10, \u001b[33m\"\u001b[39m\u001b[33maten::log10\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     45\u001b[39m     (math.log1p, \u001b[33m\"\u001b[39m\u001b[33maten::log1p\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     46\u001b[39m     (math.pow, \u001b[33m\"\u001b[39m\u001b[33maten::pow\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     47\u001b[39m     (math.sqrt, \u001b[33m\"\u001b[39m\u001b[33maten::sqrt\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     48\u001b[39m     (math.isnan, \u001b[33m\"\u001b[39m\u001b[33maten::isnan\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     49\u001b[39m     (math.asinh, \u001b[33m\"\u001b[39m\u001b[33maten::asinh\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     50\u001b[39m     (math.atanh, \u001b[33m\"\u001b[39m\u001b[33maten::atanh\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     51\u001b[39m     (math.cosh, \u001b[33m\"\u001b[39m\u001b[33maten::cosh\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     52\u001b[39m     (math.sinh, \u001b[33m\"\u001b[39m\u001b[33maten::sinh\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     53\u001b[39m     (math.tanh, \u001b[33m\"\u001b[39m\u001b[33maten::tanh\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     54\u001b[39m     (math.acos, \u001b[33m\"\u001b[39m\u001b[33maten::acos\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     55\u001b[39m     (math.asin, \u001b[33m\"\u001b[39m\u001b[33maten::asin\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     56\u001b[39m     (math.atan, \u001b[33m\"\u001b[39m\u001b[33maten::atan\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     57\u001b[39m     (math.atan2, \u001b[33m\"\u001b[39m\u001b[33maten::atan2\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     58\u001b[39m     (math.cos, \u001b[33m\"\u001b[39m\u001b[33maten::cos\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     59\u001b[39m     (math.sin, \u001b[33m\"\u001b[39m\u001b[33maten::sin\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     60\u001b[39m     (math.tan, \u001b[33m\"\u001b[39m\u001b[33maten::tan\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     61\u001b[39m     (math.asinh, \u001b[33m\"\u001b[39m\u001b[33maten::asinh\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     62\u001b[39m     (math.atanh, \u001b[33m\"\u001b[39m\u001b[33maten::atanh\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     63\u001b[39m     (math.acosh, \u001b[33m\"\u001b[39m\u001b[33maten::acosh\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     64\u001b[39m     (math.fmod, \u001b[33m\"\u001b[39m\u001b[33maten::fmod\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     65\u001b[39m     (math.modf, \u001b[33m\"\u001b[39m\u001b[33maten::modf\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     66\u001b[39m     (math.factorial, \u001b[33m\"\u001b[39m\u001b[33maten::factorial\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     67\u001b[39m     (math.frexp, \u001b[33m\"\u001b[39m\u001b[33maten::frexp\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     68\u001b[39m     (math.isinf, \u001b[33m\"\u001b[39m\u001b[33maten::isinf\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     69\u001b[39m     (math.degrees, \u001b[33m\"\u001b[39m\u001b[33maten::degrees\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     70\u001b[39m     (math.radians, \u001b[33m\"\u001b[39m\u001b[33maten::radians\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     71\u001b[39m     (cmath.isnan, \u001b[33m\"\u001b[39m\u001b[33maten::isnan\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     72\u001b[39m     (cmath.isfinite, \u001b[33m\"\u001b[39m\u001b[33maten::isfinite\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     73\u001b[39m     (cmath.isinf, \u001b[33m\"\u001b[39m\u001b[33maten::isinf\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     74\u001b[39m     (cmath.phase, \u001b[33m\"\u001b[39m\u001b[33maten::angle\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     75\u001b[39m     (cmath.rect, \u001b[33m\"\u001b[39m\u001b[33maten::polar\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     76\u001b[39m     (cmath.log, \u001b[33m\"\u001b[39m\u001b[33maten::log\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     77\u001b[39m     (cmath.log10, \u001b[33m\"\u001b[39m\u001b[33maten::log10\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     78\u001b[39m     (cmath.sqrt, \u001b[33m\"\u001b[39m\u001b[33maten::sqrt\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     79\u001b[39m     (cmath.exp, \u001b[33m\"\u001b[39m\u001b[33maten::exp\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     80\u001b[39m     (cmath.sin, \u001b[33m\"\u001b[39m\u001b[33maten::sin\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     81\u001b[39m     (cmath.tan, \u001b[33m\"\u001b[39m\u001b[33maten::tan\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     82\u001b[39m     (cmath.cos, \u001b[33m\"\u001b[39m\u001b[33maten::cos\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     83\u001b[39m     (cmath.asin, \u001b[33m\"\u001b[39m\u001b[33maten::asin\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     84\u001b[39m     (cmath.acos, \u001b[33m\"\u001b[39m\u001b[33maten::acos\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     85\u001b[39m     (cmath.atan, \u001b[33m\"\u001b[39m\u001b[33maten::atan\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     86\u001b[39m     (cmath.sinh, \u001b[33m\"\u001b[39m\u001b[33maten::sinh\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     87\u001b[39m     (cmath.cosh, \u001b[33m\"\u001b[39m\u001b[33maten::cosh\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     88\u001b[39m     (cmath.tanh, \u001b[33m\"\u001b[39m\u001b[33maten::tanh\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     89\u001b[39m     (cmath.asinh, \u001b[33m\"\u001b[39m\u001b[33maten::asinh\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     90\u001b[39m     (cmath.acosh, \u001b[33m\"\u001b[39m\u001b[33maten::acosh\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     91\u001b[39m     (cmath.atanh, \u001b[33m\"\u001b[39m\u001b[33maten::atanh\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     92\u001b[39m     (math.ldexp, \u001b[33m\"\u001b[39m\u001b[33maten::ldexp\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     93\u001b[39m     (torch._assert, \u001b[33m\"\u001b[39m\u001b[33maten::_assert\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     (\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m.grad, \u001b[33m\"\u001b[39m\u001b[33maten::grad\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     95\u001b[39m     (torch.autograd.backward, \u001b[33m\"\u001b[39m\u001b[33maten::backward\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     96\u001b[39m     (torch._C._infer_size, \u001b[33m\"\u001b[39m\u001b[33maten::_infer_size\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     97\u001b[39m     (torch.nn.functional._no_grad_embedding_renorm_, \u001b[33m\"\u001b[39m\u001b[33maten::_no_grad_embedding_renorm_\u001b[39m\u001b[33m\"\u001b[39m),  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m     98\u001b[39m     (torch.nn.functional.assert_int_or_pair, \u001b[33m\"\u001b[39m\u001b[33maten::_assert_int_or_pair\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     99\u001b[39m     (torch.nn.init._no_grad_fill_, \u001b[33m\"\u001b[39m\u001b[33maten::_no_grad_fill_\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    100\u001b[39m     (torch.nn.init._no_grad_normal_, \u001b[33m\"\u001b[39m\u001b[33maten::_no_grad_normal_\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    101\u001b[39m     (torch.nn.init._no_grad_uniform_, \u001b[33m\"\u001b[39m\u001b[33maten::_no_grad_uniform_\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    102\u001b[39m     (torch.nn.init._no_grad_zero_, \u001b[33m\"\u001b[39m\u001b[33maten::_no_grad_zero_\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    103\u001b[39m     (torch._C._get_tracing_state, \u001b[33m\"\u001b[39m\u001b[33maten::_get_tracing_state\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    104\u001b[39m     (torch._C._get_cpu_capability, \u001b[33m\"\u001b[39m\u001b[33maten::_get_cpu_capability\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    105\u001b[39m     (warnings.warn, \u001b[33m\"\u001b[39m\u001b[33maten::warn\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    106\u001b[39m     (torch._VF.stft, \u001b[33m\"\u001b[39m\u001b[33maten::stft\u001b[39m\u001b[33m\"\u001b[39m),  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    107\u001b[39m     (torch._VF.istft, \u001b[33m\"\u001b[39m\u001b[33maten::istft\u001b[39m\u001b[33m\"\u001b[39m),  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    108\u001b[39m     (torch._VF.cdist, \u001b[33m\"\u001b[39m\u001b[33maten::cdist\u001b[39m\u001b[33m\"\u001b[39m),  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    109\u001b[39m     (torch._VF.norm, \u001b[33m\"\u001b[39m\u001b[33maten::norm\u001b[39m\u001b[33m\"\u001b[39m),  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    110\u001b[39m     (torch._VF.unique_dim, \u001b[33m\"\u001b[39m\u001b[33maten::unique_dim\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    111\u001b[39m     (torch._VF.unique_consecutive, \u001b[33m\"\u001b[39m\u001b[33maten::unique_consecutive\u001b[39m\u001b[33m\"\u001b[39m),  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    112\u001b[39m     (torch._VF.nuclear_norm, \u001b[33m\"\u001b[39m\u001b[33maten::nuclear_norm\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    113\u001b[39m     (torch._VF.frobenius_norm, \u001b[33m\"\u001b[39m\u001b[33maten::frobenius_norm\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    114\u001b[39m     (torch._VF.tensordot, \u001b[33m\"\u001b[39m\u001b[33maten::tensordot\u001b[39m\u001b[33m\"\u001b[39m),  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    115\u001b[39m ]\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# ops in torch.functional are bound to torch\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# in these cases, we want to resolve the function to their python implementation\u001b[39;00m\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# instead looking up a builtin \"aten::\" schema\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_gen_torch_functional_registered_ops\u001b[39m():\n\u001b[32m    123\u001b[39m     \u001b[38;5;66;03m# eventually ops should encompass all of torch/functional.py, (torch.functional.__all__)\u001b[39;00m\n\u001b[32m    124\u001b[39m     \u001b[38;5;66;03m# but we are currently only able to compile some of the functions. additionally,\u001b[39;00m\n\u001b[32m    125\u001b[39m     \u001b[38;5;66;03m# some functions directly map to their aten:: implementations.\u001b[39;00m\n\u001b[32m    126\u001b[39m     \u001b[38;5;66;03m# TODO: add support for more ops\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: partially initialized module 'torch' has no attribute 'autograd' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763d18df",
   "metadata": {},
   "source": [
    "## **2.  Cargar dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1220bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_clean</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>besides his most recent trip to quetta mr raha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poll prestigious colleges wo nt make you happi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>house speaker paul ryan at a private dinner ea...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn president donald trump has reason to hope ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the controversial immigrationreform bill that ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       content_clean  bias\n",
       "0  besides his most recent trip to quetta mr raha...     0\n",
       "1  poll prestigious colleges wo nt make you happi...     0\n",
       "2  house speaker paul ryan at a private dinner ea...     2\n",
       "3  cnn president donald trump has reason to hope ...     0\n",
       "4  the controversial immigrationreform bill that ...     2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/data_clean/train_clean.csv\")\n",
    "\n",
    "df = df[[\"content_clean\", \"bias\"]].dropna()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdc9a71",
   "metadata": {},
   "source": [
    "## **3. División**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26b47054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 20143\n",
      "Validation: 2239\n",
      "Test: 5596\n",
      "Train: 20143\n",
      "Validation: 2239\n",
      "Test: 5596\n"
     ]
    }
   ],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"content_clean\"].tolist(),\n",
    "    df[\"bias\"].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"bias\"]\n",
    ")\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_texts,\n",
    "    train_labels,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=train_labels\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_texts)}\")\n",
    "print(f\"Validation: {len(val_texts)}\")\n",
    "print(f\"Test: {len(test_texts)}\")\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"content_clean\"].tolist(),\n",
    "    df[\"bias\"].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"bias\"]\n",
    ")\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_texts,\n",
    "    train_labels,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=train_labels\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_texts)}\")\n",
    "print(f\"Validation: {len(val_texts)}\")\n",
    "print(f\"Test: {len(test_texts)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e4cca8",
   "metadata": {},
   "source": [
    "## **4. Tokenization con DistilBERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55ca379",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\n",
    "    \"distilbert-base-uncased\"\n",
    ")\n",
    "\n",
    "def tokenize(texts):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize(train_texts)\n",
    "val_encodings   = tokenize(val_texts)\n",
    "test_encodings  = tokenize(test_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98787cda",
   "metadata": {},
   "source": [
    "## **5. Dataset PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dfa9ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Para cada ejemplo devolvemos los tensores de input_ids, attention_mask y la etiqueta\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "# Crear datasets de entrenamiento, validación y test\n",
    "train_dataset = NewsDataset(train_encodings, train_labels)\n",
    "val_dataset   = NewsDataset(val_encodings, val_labels)\n",
    "test_dataset  = NewsDataset(test_encodings, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a198c85",
   "metadata": {},
   "source": [
    "## **6. Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "788a7e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=3\n",
    ")\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c17aec4",
   "metadata": {},
   "source": [
    "## **7. Evaluación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13b950c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred                # 1. Recibe la salida del modelo y las etiquetas reales\n",
    "    preds = np.argmax(logits, axis=1)        # 2. Convierte los logits en la clase predicha\n",
    "    \n",
    "    acc = accuracy_score(labels, preds)      # 3. Calcula Accuracy\n",
    "    f1  = f1_score(labels, preds, average=\"macro\")  # 4. Calcula Macro-F1 (útil para clases desbalanceadas)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"macro_f1\": f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a147e655",
   "metadata": {},
   "source": [
    "## **8. Entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40019a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    # evaluation_strategy=\"steps\",   # <-- quitar\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    save_total_limit=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70810b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aaron\\AppData\\Local\\Temp\\ipykernel_19768\\3012789700.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18e8f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a51f37",
   "metadata": {},
   "source": [
    "## **9. Evaluación final**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac86ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5695ac42",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
